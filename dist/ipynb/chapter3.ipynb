{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b62fc9",
   "metadata": {},
   "source": [
    "# Apprentissage Supervisé {#ch2}\n",
    "\n",
    "Dans ce chapitre, nous allons explorer l'apprentissage supervisé. Ce\n",
    "type d'apprentissage, aussi connu sous le nom d'apprentissage avec\n",
    "tutelle (maître), permet de déterminer la relation qui existe entre une\n",
    "variable explicative $\\mathbf{X}$ et une variable à expliquer\n",
    "(étiquette) $\\mathbf{y}$. En d'autres termes, l'apprentissage supervisé\n",
    "est le processus permettant à un modèle d'apprendre, en lui fournissant\n",
    "des données d'entrée ainsi que des données de sortie. Cette paire\n",
    "d'entrée/sortie est généralement appelée «données étiquetées». Dans un\n",
    "cadre illustratif, pensez à un enseignant qui, connaissant la bonne\n",
    "réponse à une question, évaluera un élève en fonction de l'exactitude de\n",
    "sa réponse à cette question. Pour plus de clarification, comparons\n",
    "l'approche de l'apprentissage automatique à la programmation\n",
    "traditionnelle.\n",
    "\n",
    "- Dans la programmation traditionnelle, comme illustré dans la figure\n",
    "  [1.1](#fig:tradi_prog){reference-type=\"ref\"\n",
    "  reference=\"fig:tradi_prog\"}, nous avons une fonction $f$ connue qui\n",
    "  reçoit la donnée en entrée $\\mathbf{x}$ et renvoie la réponse\n",
    "  correspondante $\\mathbf{y}$ en sortie. Par exemple, nous pouvons\n",
    "  penser à écrire une fonction $f$ qui calcule le carré d'un nombre;\n",
    "  si nous donnons en entrée le nombre $2$, notre programme va nous\n",
    "  renvoyer la valeur $\\displaystyle f(2) = 2^2 = 4 = y$.\n",
    "\n",
    "  ![L'approche\n",
    "traditionnelle](images/traditional_programming.png){#fig:tradi_prog\n",
    "  width=\"0.5\\\\linewidth\"}\n",
    "\n",
    "- L'approche de la programmation utilisée dans l'apprentissage\n",
    "  automatique est tout à fait différente de la précédente. Dans cette\n",
    "  dernière, nous ne connaissons pas la fonction $f$ et nous voulons\n",
    "  donc l'approximer par une fonction $\\hat{f}$ en utilisant les\n",
    "  données à notre disposition. Cette approche est donc divisée en deux\n",
    "  phases. La première est la phase où nous entraînons notre fonction\n",
    "  $\\hat{f}$ (figure [1.2](#fig:ML_prog_train){reference-type=\"ref\"\n",
    "  reference=\"fig:ML_prog_train\"}). Si nous revenons à notre exemple\n",
    "  précédent, cette étape pourra consister à présenter à la fonction\n",
    "  $\\hat{f}$, plusieurs couples de nombres et leurs carrés\n",
    "  $\\{(2, 4), (3, 9), (4, 16), \\cdots\\}$. L'objectif ici est de trouver\n",
    "  un moyen d'estimer la fonction \\\"carrée\\\" en observant uniquement\n",
    "  les données à notre disposition.\n",
    "\n",
    "  ![L'approche apprentissage\n",
    "automatique](images/ML_Programming_flow_Training.png){#fig:ML_prog_train\n",
    "  width=\"0.5\\\\linewidth\"}\n",
    "\n",
    "  La dernière étape consiste à fournir un nouveau nombre à notre\n",
    "  fonction $f^\\star$, obtenue après l'étape $1$, afin qu'elle prédise\n",
    "  (_approximativement_) le carré de ce nombre.\n",
    "\n",
    "  ![L'approche apprentissage\n",
    "automatique](images/ML_Programming_flow_Testing.png){#fig:ML_prog_test\n",
    "  width=\"0.6\\\\linewidth\"}\n",
    "\n",
    "  Dans la suite du cours, nous reviendrons beaucoup plus en détails\n",
    "  sur les étapes ci-dessus présentées.\n",
    "\n",
    "L'apprentissage supervisé est souvent utilisé pour deux types de\n",
    "problèmes: les problèmes de régression et les problèmes de\n",
    "classification.\n",
    "\n",
    "## Problèmes de Régression\n",
    "\n",
    "Dans l'apprentissage supervisé, on parle de problèmes de régression\n",
    "lorsque la variable à expliquer $\\mathbf{y}$ est continue. Par exemple\n",
    "lorsqu'on veut **prédire le prix** d'une bouteille de vin sur la base de\n",
    "**certaines variables** (le pays de fabrication, qualité, le taux\n",
    "d'alcool, etc.). Il s'agit bel et bien d'un problème de régression.\n",
    "\n",
    "### La Régression Linéaire\n",
    "\n",
    "La régression linéaire est un problème de régression pour lequel le\n",
    "modèle ou la fonction dépend linéairement de ses paramètres [@reg_lin].\n",
    "Les différents types de régression linéaire que nous connaissons sont la\n",
    "régression linéaire affine, la régression linéaire polynomiale et la\n",
    "régression linéaire à fonctions de base radiales. Dans ce document, nous\n",
    "allons nous focaliser sur deux types fondamentaux de régression\n",
    "linéaire: la régression linéaire affine et la régression linéaire\n",
    "polynomiale.\n",
    "\n",
    "#### La régression linéaire affine\n",
    "\n",
    "Une régression linéaire de paramètre $\\boldsymbol{\\theta}$ est dite\n",
    "affine si pour tout $\\mathbf{x} \\in \\mathbb{R}^d.$\n",
    "\n",
    "$$\n",
    "f_{\\boldsymbol{\\theta}}(\\mathbf{x}) = \\boldsymbol{\\theta}_{0} + \\boldsymbol{\\theta}_{1}^{T} \\mathbf{x} = \\begin{bmatrix} \\boldsymbol{\\theta}_0 & \\boldsymbol{\\theta}_1^{T} \\end{bmatrix} \\begin{bmatrix}\n",
    "1 \\\\\n",
    "\\mathbf{x}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "avec $\\boldsymbol{\\theta}_0 \\in \\mathbb{R}$ et\n",
    "$\\boldsymbol{\\theta}_1 \\in \\mathbb{R}^d.$ Le terme\n",
    "$\\left[ 1, \\mathbf{x}\\right]$ est appelé attribut du modèle et il sera\n",
    "noté par $\\phi(\\mathbf{x}).$\n",
    "\n",
    "::: {.center}\n",
    "![Représentation graphique d'un exemple de données d'entraînement\n",
    "](images/linearReg_im1.png){#exdonnee width=\"60%\"}\n",
    ":::\n",
    "\n",
    "Les jeux de données représentés dans la figure\n",
    "[1.4](#exdonnee){reference-type=\"ref\" reference=\"exdonnee\"} forment un\n",
    "ensemble d'entraînement où la régression linéaire affine sera la plus\n",
    "appropriée.\\\n",
    "Pour déterminer les meilleurs paramètres de la régression linéaire\n",
    "affine deux différentes méthodes sont utilisées à savoir: la méthode\n",
    "explicite et la méthode approximative.\n",
    "\n",
    "- **La méthode explicite**\n",
    "\n",
    "  Dans le cas de la régression linéaire affine, la méthode explicite\n",
    "  peut-être utilisée par le biais de l'estimation du maximum de\n",
    "  vraisemblance qui interpelle la notion de probabilité\n",
    "  conditionnelle.\n",
    "\n",
    "  Pour être plus concret, nous allons considérer l'expression\n",
    "  suivante:\\\n",
    "   $y_i = f_{\\boldsymbol{\\theta}} (\\mathbf{x}_i) + \\varepsilon~~~$ avec\n",
    "  $\\varepsilon \\sim N(0, \\sigma^2)$.\n",
    "\n",
    "  Dans cette expression, nous supposons que $f$ est la fonction que\n",
    "  nous allons estimer à partir de son paramètre $\\boldsymbol{\\theta}$\n",
    "  et qui nous permettra de faire nos prédictions pour chaque élément\n",
    "  donné à partir du domaine d'entraînement. Nous noterons par $\\hat f$\n",
    "  comme étant la fonction estimée de $f$.\n",
    "\n",
    "  Pour une suite de points\n",
    "  $(\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2),..., (\\mathbf{x}_n, y_n)$\n",
    "  représentant le domaine d'entraînement nous supposons que les $y_i$\n",
    "  suivent chacun une loi normale et qu'ils sont aussi indépendants et\n",
    "  identiquement distribués (i.i.d).\n",
    "\n",
    "  Alors, nous avons\n",
    "  $\\mathbf{x} = \\left\\lbrace \\mathbf{x}_1, \\mathbf{x}_2, ..., \\mathbf{x}_n\\right\\rbrace  \\in \\mathbb{R}^{n \\times d}$\n",
    "  et\n",
    "  $\\mathbf{y} = \\left\\lbrace y_1, y_2, ..., y_n\\right\\rbrace  \\in \\mathbb{R}^{n}$.\n",
    "\n",
    "  Déterminons le paramètre $\\boldsymbol{\\theta} ^{*}$ qui maximise la\n",
    "  vraisemblance. $$\\begin{aligned}\n",
    "    \\mathbb{P}(y_1, y_2,.., y_n|  \\mathbf{x}_1, \\mathbf{x}_2, \\cdots \\mathbf{x}_n; \\boldsymbol{\\theta}) &= \\mathbb{P}(\\mathbf{y}|\\mathbf{x}; \\boldsymbol{\\theta}) \n",
    "    \\\\\n",
    "    &= \\prod_{i}^{n}\\mathbb{P}(y_i| \\mathbf{x}_i, \\boldsymbol{\\theta})~~ \\text{avec }  y_i \\sim N(\\boldsymbol{\\theta}^T \\mathbf{x}_i; \\sigma^2)\\end{aligned}$$\n",
    "  Dans ce cas nous avons:\n",
    "\n",
    "  $$\\mathbb{P}(y_i| \\mathbf{x}_i; \\boldsymbol{\\theta}) = \\frac{1}{\\sigma \\sqrt{2\\pi }}\\exp \\left(-\\frac{(yi - \\boldsymbol{\\theta}^T \\mathbf{x_i})^2}{2 \\sigma^2}\\right).$$\n",
    "\n",
    "  Nous savons que, la fonction logarithme est une fonction strictement\n",
    "  croissante, ce qui implique que le paramètre\n",
    "  $\\boldsymbol{\\theta} ^*$ qui maximise la vraisemblance maximise\n",
    "  aussi le logarithme-vraisemblance. Ainsi, en appliquant le\n",
    "  logarithme de la vraisemblance, nous avons:\\\n",
    "   $$\\log \\mathbb{P}(\\mathbf{y}|  \\mathbf{x}; \\boldsymbol{\\theta}) = \\sum_{i=1}^{n} \\log \\mathbb{P}(y_i| \\mathbf{x}_i; \\boldsymbol{\\theta}).$$\n",
    "\n",
    "  Pour chaque\n",
    "  $i \\in \\left\\lbrace 1, 2, ..., n\\right\\rbrace  ,~\\log \\mathbb{P} (y_i| \\mathbf{x}_i; \\boldsymbol{\\theta}) =\\log\\left(\\frac{1}{\\boldsymbol{\\sigma} \\sqrt{2\\pi}}\\right)~ -\\frac{\\left(y_i - \\boldsymbol{\\theta}^T \\mathbf{x}_i\\right)^2}{2 \\sigma^2}$\n",
    "\n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "  \\implies \\log \\mathbb{P} (\\mathbf{y}| \\mathbf{x}; \\boldsymbol{\\theta}) &= -\\frac{1}{2 \\sigma^2} \\sum_{i=1}^{n}(y_i - \\boldsymbol{\\theta}^T \\mathbf{x}_i)^2 +c^{ste}\n",
    "  \\\\\n",
    "  \\\\\n",
    "  &= -\\frac{1}{2 \\sigma^2} (\\mathbf{y} - \\boldsymbol{\\theta} \\mathbf{x})^T (\\mathbf{y} - \\boldsymbol{\\theta} \\mathbf{x}) + c^{ste}\\end{aligned}\n",
    "  $$\n",
    "\n",
    "  Ainsi, la dérivée partielle du logarithme de la vraisemblance par\n",
    "  rapport à $\\boldsymbol{\\theta}$ est donnée par:\n",
    "\n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "  \\dfrac{\\partial \\log \\mathbb{P} (\\mathbf{y}| \\mathbf{x}, \\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta}} & = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left( -\\frac{1}{2 \\sigma^2} (\\mathbf{y} - \\mathbf{x} \\boldsymbol{\\theta})^T (\\mathbf{y} - \\mathbf{x} \\boldsymbol{\\theta} ) + c^{ste} \\right)\n",
    "  \\\\\n",
    "  \\\\\n",
    "  %& =  -\\frac{1}{\\sigma^2} (y - \\boldsymbol{\\theta} X)^T (y - \\boldsymbol{\\theta} X)\n",
    "  & = \\frac{1}{\\sigma^2} \\mathbf{x}^T(\\mathbf{x}\\boldsymbol{\\theta} - \\mathbf{y}).\\end{aligned}\n",
    "  $$\n",
    "\n",
    "  Alors, résoudre l'équation: $$\n",
    "      \\displaystyle \\frac{\\partial \\log \\mathbb{P}(\\mathbf{y}| \\mathbf{x}, \\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta}} = 0$$\n",
    "  nous permettra de trouver la valeur de $\\boldsymbol{\\theta}^*$.\n",
    "\n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "      \\frac{\\partial \\log \\mathbb{P}(\\mathbf{y}| \\mathbf{x}, \\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta}} &=0,\\\\\n",
    "      \\mathbf{x}^T(\\mathbf{x}\\boldsymbol{\\theta} - \\mathbf{y}) &= 0, \\\\\n",
    "      \\mathbf{x}^T\\mathbf{x}\\boldsymbol{\\theta} &= \\mathbf{x}^T\\mathbf{y}.\\end{aligned}\n",
    "  $$\n",
    "\n",
    "  En supposant que la matrice $\\mathbf{x}^T\\mathbf{x}$ est inversible\n",
    "  nous avons : $$\n",
    "    \\boldsymbol{\\theta}^{*} = (\\mathbf{x}^T\\mathbf{x})^{-1}\\mathbf{x}^T\\mathbf{y}.$$\n",
    "\n",
    "  Alors, vu que nous avons déterminé le paramètre\n",
    "  $\\boldsymbol{\\theta}^{*}$, la fonction $\\hat{\\boldsymbol{f}}$\n",
    "  associée au paramètre $\\boldsymbol{\\theta}^{*}$, souvent appelée\n",
    "  \\\"hypothèse\\\" ou \\\"modèle\\\" s'écrit comme\n",
    "  $$\\hat{\\boldsymbol{f}}(\\mathbf{x}) = \\boldsymbol{\\theta}^{*}\\mathbf{x}.$$\n",
    "\n",
    "  [\\[droite\\]]{#droite label=\"droite\"}\n",
    "\n",
    "  ::: {.center}\n",
    "  ![Représentation graphique de la fonction $\\hat{f}$ définie dans\n",
    "l'ensemble $X$ à valeur dans\n",
    "$\\mathbb{R}$.](images/linearReg_im3.png){#droitelin width=\"50%\"}\n",
    "  :::\n",
    "\n",
    "  La méthode explicite nous permet d'obtenir la solution exacte de\n",
    "  l'équation [\\[equat\\]](#equat){reference-type=\"eqref\"\n",
    "  reference=\"equat\"}. Tout de même, trouver cette solution exacte est\n",
    "  souvent très compliquée dans le cas où l'étude se fait sur un grand\n",
    "  ensemble de jeux de données (la complexité pour trouver l'inverse\n",
    "  dans l'équation [\\[star\\]](#star){reference-type=\"eqref\"\n",
    "  reference=\"star\"} est $\\mathcal{O}(n^{3})$). Pour cela, dans ce qui\n",
    "  suit, nous allons présenter des méthodes alternatives qui nous\n",
    "  permettront de donner une valeur approchée à la solution exacte.\n",
    "\n",
    "- **Méthodes approximatives**\n",
    "\n",
    "  Dans cette partie, nous allons utiliser une méthode itérative pour\n",
    "  estimer la valeur des paramètres de l'équation suivante:\\\n",
    "\n",
    "  $$\n",
    "  \\mathbf{y}=\\boldsymbol{\\theta} \\mathbf{x}\n",
    "    $$,\\\n",
    "  où $\\boldsymbol{\\theta} \\in \\mathbb{R}^{d+1}$ est le vecteur de\n",
    "  paramètres à estimer;\n",
    "  $\\mathbf{X} = \\left\\lbrace \\mathbf{x}_1, \\mathbf{x}_2, ..., \\mathbf{x}_n\\right\\rbrace  \\in \\mathbb{R}^{n \\times (d+1)}$\n",
    "  et\n",
    "  $\\mathbf{y} = \\left\\lbrace y_1, y_2, ..., y_n\\right\\rbrace  \\in \\mathbb{R}^{n}$\n",
    "  les données.\n",
    "  $$\n",
    "\n",
    "  **La fonction de perte**\n",
    "\n",
    "  La fonction de perte mesure la différence entre la valeur observée\n",
    "  et la valeur estimée. En apprentissage automatique, l'objectif est\n",
    "  d'optimiser la fonction de perte. Il existe différentes fonctions de\n",
    "  perte selon le critère (ou métrique permettant d'évaluer la\n",
    "  performance du modèle) adopté(e). Dans cette partie, nous allons\n",
    "  utiliser l'erreur quadratique moyenne (appelé Mean Square Error\n",
    "  (MSE) en anglais) pour définir notre fonction de perte.\n",
    "\n",
    "  L'erreur quadratique moyenne entre le $\\mathbf{y}$ observé et le\n",
    "  $\\mathbb{\\hat{y}}$ prédit est donnée par:\n",
    "\n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "  \\operatorname{MSE}(\\mathbf{y}, \\hat{\\boldsymbol{y}}) & = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2,\\end{aligned}\n",
    "  $$\n",
    "\n",
    "  où $n$ est la dimension des vecteurs $\\mathbf{y}$ et\n",
    "  $\\hat{\\boldsymbol{y}}$.\n",
    "\n",
    "  Dans le cas de la régression linéaire, cette fonction peut être\n",
    "  réécrite comme étant une fonction $E$ de $\\boldsymbol{\\theta}$.\n",
    "  $$E\\left(\\boldsymbol{\\theta}\\right)  = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\boldsymbol{\\theta}^{T} \\mathbf{x}_i)^2.$$\n",
    "\n",
    "  Par conséquent, le paramètre $\\boldsymbol{\\theta}$ qui correspond à\n",
    "  la meilleure ligne d'ajustement sera tout simplement la valeur qui\n",
    "  minimise la fonction de perte $E$. Pour cela, nous allons introduire\n",
    "  une méthode la plus souvent utilisée pour minimiser une fonction\n",
    "  (éventuellement convexe) dans l'apprentissage automatique à savoir\n",
    "  la descente de gradient.\n",
    "\n",
    "  [\\[f_convexe\\]]{#f_convexe label=\"f_convexe\"}\n",
    "\n",
    "  ::: {.center}\n",
    "  ![Représentation graphique d'une fonction\n",
    "convexe](images/linearReg_im2.png){#f_convexe width=\"40%\"}\n",
    "  :::\n",
    "\n",
    "#### Descente de gradient {GD}\n",
    "\n",
    "La descente de gradient est une procédure itérative d'optimisation\n",
    "dans laquelle, à chaque étape, on améliore la solution en essayant\n",
    "de minimiser la fonction de perte considérée [@desc_grad]. Elle est\n",
    "appliquée lorsque l'on cherche le minimum d'une fonction dont on\n",
    "connaît l'expression analytique, qui est dérivable, mais dont le\n",
    "calcul direct du minimum est difficile.\n",
    "\n",
    "Pour entamer cette procédure, nous allons commencer par initialiser\n",
    "le paramètre $\\boldsymbol{\\theta}$. Ensuite, nous calculons la\n",
    "dérivée partielle de la fonction $E$ par rapport au paramètre\n",
    "$\\boldsymbol{\\theta}$ donnée par:\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}} = -\\frac{2}{n} \\sum_{i=1}^{n} \\mathbf{x}_i(y_i - \\boldsymbol{\\theta}^{T} \\mathbf{x}_i).$$\n",
    "\n",
    "Pour trouver les meilleurs paramètres, nous allons répéter le\n",
    "processus ci-dessous jusqu'à ce que la fonction de perte soit très\n",
    "proche ou égale à $0$.\n",
    "\n",
    "$$\\boldsymbol{\\theta} = \\boldsymbol{\\theta} - \\gamma \\cdot \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}},$$\n",
    "\n",
    "La valeur de $\\boldsymbol{\\theta}$ trouvée après convergence est la\n",
    "valeur optimale que nous noterons par $\\boldsymbol{\\theta}^*$.\n",
    "\n",
    "Alors, concernant l'exemple de la figure\n",
    "[1.4](#exdonnee){reference-type=\"ref\" reference=\"exdonnee\"}, notre\n",
    "hypothèse ou modèle sera représenté par une droite d'ajustement de\n",
    "la même forme que celle en couleur verte sur la figure\n",
    "[1.5](#droitelin){reference-type=\"ref\" reference=\"droitelin\"}. Cette\n",
    "droite est d'équation:\n",
    "\n",
    "::: {.center}\n",
    "$\\mathbf{y} = \\boldsymbol{\\theta}^*\\mathbf{x}$.\n",
    ":::\n",
    "\n",
    "**Implementation**\\\n",
    "\n",
    "::: {.algorithm}\n",
    "::: {.algorithmic}\n",
    "class **LinearRégression**():    def **\\_\\_init\\_\\_** (self):       pass\n",
    "   def **fonction_perte**(self, y_vrai, y_prédit):       définit une\n",
    "fonction de perte et retourne sa valeur    def **algorithme**(self,\n",
    "$\\mathbf{x}$, $\\mathbf{y}$, taux_apprentissage, nombre_itération):\n",
    "      initialiser les paramètres $\\boldsymbol{\\theta}_0$ et\n",
    "$\\boldsymbol{\\theta}_1$\n",
    "\n",
    "for i in range(nombre_itération):           **prédiction**(x),\n",
    "          calcule la perte au moyen de **fonction_perte**,          \n",
    "mise à jour des paramètres $\\boldsymbol{\\theta}_0$ et\n",
    "$\\boldsymbol{\\theta}_1$,           return $\\boldsymbol{\\theta}_0$,\n",
    "$\\boldsymbol{\\theta}_1$,    def **prédiction**(self, $\\mathbf{x}$):\n",
    "      y_prédit\n",
    "$= \\boldsymbol{\\theta}_0^T \\mathbf{x} +  \\boldsymbol{\\theta}_1$,\n",
    "      return y_prédit\n",
    ":::\n",
    ":::\n",
    "\n",
    "Un exemple d'implementation de régression linéaire est disponible\n",
    "[ici](https://colab.research.google.com/drive/1Ad94wJI2hch6BxpRV9P-SZcc3UfI2zwY#scrollTo=BPyCNZ9Z6tMg)\n",
    "\n",
    "#### La régression linéaire polynomiale\n",
    "\n",
    "La régression linéaire de paramètre $\\boldsymbol{\\theta}$ est dite\n",
    "polynomiale si pour tout $\\mathbf{x} \\in \\mathbb{R}^d,$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{f}_{\\boldsymbol{\\theta}}(\\mathbf{x}) &= \\boldsymbol{\\theta}_0 + \\boldsymbol{\\theta}_1 \\mathbf{x}^1 +...+ \\boldsymbol{\\theta}_m \\mathbf{x}^{m}\n",
    "\\\\\n",
    "&= \\left[ \\boldsymbol{\\theta}_0, \\boldsymbol{\\theta}_1, ..., \\boldsymbol{\\theta}_m\\right] \\begin{bmatrix}\n",
    "1 \\\\\n",
    "\\mathbf{x}^{1} \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{x}^{m}\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "&=\\sum_{i=0}^{m} \\boldsymbol{\\theta}_i \\mathbf{x}^{i},\\end{aligned}\n",
    "$$\n",
    "\n",
    "avec comme attribut le vecteur\n",
    "$\\phi (\\mathbf{x}) = \\left[ 1, \\mathbf{x}^1, ..., \\mathbf{x}^m\\right]^T$.\n",
    "Ainsi, deux méthodes existent pour déterminer le meilleur paramètre\n",
    "$\\boldsymbol{\\theta}^*$.\n",
    "\n",
    "1.  **Estimation par la méthode du maximum de vraisemblance (appelée\n",
    "    MLE: Maximum Likelihood Estimation)**: Suivant de manière analogique\n",
    "    de la détermination du paramètre $\\boldsymbol{\\theta}^*$ sur la\n",
    "    partie précédente, la meilleure valeur du paramètre\n",
    "    $\\boldsymbol{\\theta}^{*}$ est déterminée par\n",
    "    $\\boldsymbol{\\theta}^*= (\\mathbf{x}^T \\mathbf{x})^{-1}\\mathbf{x}^T\\mathbf{y}.$\n",
    "\n",
    "2.  **Estimation par la méthode d'un posteriori maximal (appelée MAP:\n",
    "    Maximum A Posteriori)**: La méthode consiste à trouver la valeur\n",
    "    $\\boldsymbol{\\theta}^{*}_{\\mathrm{MAP}}$ qui maximise le produit\n",
    "    entre la vraisemblance et la distribution à priori des paramètres\n",
    "    $\\boldsymbol{\\theta}$ comme l'indique l'équation\n",
    "    [\\[naivebayes\\]](#naivebayes){reference-type=\"ref\"\n",
    "    reference=\"naivebayes\"}. Cette méthode d'estimation apparaît\n",
    "    généralement dans un cadre bayésien. Tout comme la méthode du\n",
    "    maximum de vraisemblance, elle peut être utilisée afin d'estimer un\n",
    "    certain nombre de paramètres inconnus, comme les paramètres d'une\n",
    "    densité de probabilité, reliés à un échantillon donné. La seule\n",
    "    différence avec la méthode de maximum de vraisemblance est sa\n",
    "    possibilité de prendre en compte un à priori non uniforme sur les\n",
    "    paramètres à estimer. Ainsi, nous pouvons dire que l'estimateur au\n",
    "    maximum de vraisemblance est l'estimateur MAP pour une distribution\n",
    "    à priori uniforme.\n",
    "    Par le théorème de Bayes, nous pouvons obtenir le postérieur comme\n",
    "    un produit de vraisemblance avec :\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "            \\mathbb{P}\\left(\\boldsymbol{\\theta}|\\mathbf{y};\\mathbf{x} \\right) &= \\frac{\\mathbb{P}\\left(\\mathbf{y};\\mathbf{x}|\\boldsymbol{\\theta}\\right) \\mathbb{P}\\left(\\boldsymbol{\\theta} \\right)}{\\mathbb{P}\\left(\\mathbf{y};\\mathbf{x}\\right)}\n",
    "            \\\\\n",
    "            & \\propto \\mathbb{P}\\left(\\mathbf{y};\\mathbf{x}|\\boldsymbol{\\theta}\\right)\\mathbb{P}\\left(\\boldsymbol{\\theta}\\right).\\nonumber\n",
    "        \\end{aligned}\n",
    "    $$\n",
    "\n",
    "Avec\n",
    "$\\mathbf{Y}| \\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{\\theta}^T \\mathbf{x}, \\sigma^2)$\n",
    "et\n",
    "$\\boldsymbol{\\theta} \\sim \\mathcal{N}(\\mathbf{0}, \\lambda^2 \\mathbf{I})$\n",
    "où $\\mathbf{I}$ représente la matrice identité dont la dimension est la\n",
    "longueur du vecteur $\\boldsymbol{\\theta}$. Ainsi, nous pouvons écrire la\n",
    "vraisemblance comme:\n",
    "$$\\mathbb{P}(\\boldsymbol{\\theta}| \\mathbf{y};\\mathbf{x}) = \\frac{1}{\\sigma \\sqrt{2\\pi }}\\exp{\\left(-\\frac{(y - \\boldsymbol{\\theta}^T \\mathbf{x})^2}{2 \\sigma^2}\\right)} \\frac{1}{\\lambda \\sqrt{2\\pi }} \\operatorname{exp}\\left(-\\frac{\\boldsymbol{\\theta}^2}{2 \\lambda^2}\\right)$$\n",
    "\n",
    "En utilisant la fonction logarithme, nous avons $$\\begin{aligned}\n",
    " \\log \\mathbb{P}(\\boldsymbol{\\theta}|\\mathbf{x}, \\mathbf{y}) &= \\log\\left(\\frac{1}{\\sigma \\sqrt{2\\pi }}\\operatorname{exp}\\left(-\\frac{(\\mathbf{y} - \\boldsymbol{\\theta}^T \\mathbf{x})^2}{2 \\sigma^2}\\right) \\frac{1}{\\lambda \\sqrt{2\\pi }}\\exp{\\left(-\\frac{\\boldsymbol{\\theta}^2}{2 \\lambda^2}\\right)} \\right)\\\\\n",
    " &= -\\frac{1}{2 \\sigma^2}(\\mathbf{y} - \\boldsymbol{\\theta}^T \\mathbf{x})^2 -\\frac{1}{2 \\lambda^2}\\boldsymbol{\\theta} ^2 + c^{te} \n",
    "\\\\\n",
    "& = -\\frac{1}{2 \\sigma^2}||\\mathbf{y} - \\boldsymbol{\\theta} \\mathbf{x}||^2 -\\frac{1}{2 \\lambda^2}||\\boldsymbol{\\theta}|| ^2 + c^{te}.\\end{aligned}$$\n",
    "\n",
    "Et le paramètre à estimer $\\boldsymbol{\\theta}^*$ correspond au\n",
    "$\\boldsymbol{\\theta}$ qui annule la dérivée partielle de\n",
    "$\\log \\mathbb{P}(\\mathbf{y}| \\mathbf{x}, \\boldsymbol{\\theta})$ par\n",
    "rapport à $\\boldsymbol{\\theta}$.\n",
    "\n",
    "::: {.center}\n",
    "$\\displaystyle \\frac{\\partial \\log \\mathbb{P}(\\mathbf{y}| \\mathbf{x}, \\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta}} = 0\n",
    "    \\Longleftrightarrow  \\frac{\\partial \\log}{\\partial \\boldsymbol{\\theta}}\\left(-\\frac{1}{2 \\sigma^2}||\\mathbf{y} - \\boldsymbol{\\theta} \\mathbf{x}||^2 -\\frac{1}{2 \\lambda^2}||\\boldsymbol{\\theta}||^2 + c^{te} \\right) = 0$.\n",
    ":::\n",
    "\n",
    "$\\linebreak$ Ceci revient à déterminer le $\\boldsymbol{\\theta}$ qui\n",
    "annule l'expression $$\\begin{aligned}\n",
    "  \\frac{1}{ \\sigma^2}\\mathbf{x}^T (\\mathbf{y} - \\boldsymbol{\\theta} \\mathbf{x}) -\\frac{1}{ \\lambda^2} \\boldsymbol{\\theta}. \\end{aligned}$$\n",
    "\n",
    "Alors, $$\\begin{aligned}\n",
    "    &-\\frac{1}{ \\sigma^2}\\mathbf{x}^T (\\mathbf{y} - \\boldsymbol{\\theta} \\mathbf{x}) -\\frac{1}{ \\lambda^2} \\boldsymbol{\\theta} = 0\n",
    "    \\Longleftrightarrow\n",
    "    -\\frac{1}{ \\sigma^2}\\mathbf{x}^T \\mathbf{y} + \\frac{1}{ \\sigma^2} \\boldsymbol{\\theta} \\mathbf{x}^T \\mathbf{X} - \\frac{1}{\\lambda^2}\\boldsymbol{\\theta} = 0\n",
    "    \\\\\n",
    "    \\\\\n",
    "    &~(\\frac{1}{\\sigma^2}\\mathbf{x}^T \\mathbf{x} - \\frac{1}{\\lambda^2}) \\boldsymbol{\\theta} = \\frac{1}{\\sigma^2}\\mathbf{x}^T \\mathbf{y}\n",
    "    \\Longleftrightarrow\n",
    "  \\boldsymbol{\\theta}^* = \\left(\\mathbf{x}^T \\mathbf{x} - \\frac{\\sigma^2}{\\lambda^2} \\mathbf{I} \\right)^{-1} \\mathbf{x}^T\\mathbf{y}.\\end{aligned}$$\n",
    "\n",
    "Cas Pratique\n",
    "\n",
    "## Les Problèmes de Classification\n",
    "\n",
    "A la différence avec le problème de régression, la classification est un\n",
    "autre type de problème d'apprentissage supervisé où la variable à\n",
    "prédire est discrète (ou qualitative ou catégorique). Cette variable\n",
    "discrète peut être binaire (deux classes) ou multiple (multi-classe).\n",
    "Par exemple lorsqu'on veut **catégoriser** si un e-mail reçu est un\n",
    "'spam' ou \\\"non-spam\\\" il s'agit bel et bien d'un problème de\n",
    "classification.\n",
    "\n",
    "### L'algorithme des $K$ plus proches voisins ($K$-NN)\n",
    "\n",
    "L'algorithme des $K$ plus proches voisins aussi appelé $K$-Nearest\n",
    "Neighbors ($K$-NN) en anglais est une méthode d'apprentissage supervisé\n",
    "utilisée pour la classification aussi bien que la régression :cite:`goodfellow2016deep`\n",
    "[@goodfellow2016deep]. Il est compté parmi les plus simples algorithmes\n",
    "d'apprentissage automatique supervisé, facile à mettre en oeuvre et à\n",
    "comprendre.\n",
    "\n",
    "Toutefois dans l'industrie, il est plus utilisé pour les problèmes de\n",
    "classification. Son fonctionnement se base sur le principe suivant: _dis\n",
    "moi qui sont tes voisins, je te dirais qui tu es \\..._\n",
    "\n",
    "L'objectif de cet algorithme est de déterminer la classe d'une nouvelle\n",
    "observation $x$ en fonction de la classe majoritaire parmi ses $K$ plus\n",
    "proches voisins. Donc l'algorithme est basé sur la mesure de similarité\n",
    "des voisins proches pour classifier une nouvelle observation $x$.\n",
    "\n",
    "La méthode des $K$ plus proches voisins, où $K$ représente le nombre de\n",
    "voisins proches est une méthode non-paramétrique. Cela signifie que\n",
    "l'algorithme permet de faire une classification sans faire d'hypothèse\n",
    "sur la fonction $y=f(\\mathbf{x}_1,\\mathbf{x}_2, \\dots \\mathbf{x}_n)$ qui\n",
    "relie la variable dépendante $\\mathbf{y}$ aux variables indépendantes\n",
    "$\\mathbf{x}_1,\\mathbf{x}_2, \\dots, \\mathbf{x}_n$.\n",
    "\n",
    "Soit $\\mathcal{D}$ l'ensemble des données ou l'échantillon\n",
    "d'apprentissage, défini par:\n",
    "$$\\mathcal{D}=\\{(\\mathbf{x}_i, y_i), i=1, \\dots, n\\},$$ où\n",
    "$y_i \\in \\{1,\\dots,c\\}$ dénote la classe de la donnée $i$ et\n",
    "$\\mathbf{x}_i=(\\mathbf{x}_{i1}, \\dots, \\mathbf{x}_{im})$ est le vecteur\n",
    "représentant les variables (attributs) prédictrices de la donnée $i$.\n",
    "\n",
    "Supposons un nouveau point $\\textbf{p}$ pour lequel nous voulons prédire\n",
    "la classe dans la quelle il doit appartenir comme indiqué dans la figure\n",
    "[1.7](#fig:Knn){reference-type=\"ref\" reference=\"fig:Knn\"}.\n",
    "\n",
    "![Classification d'un nouveau point entre deux\n",
    "classes](images/KNN.png){#fig:Knn width=\"0.6\\\\linewidth\"}\n",
    "\n",
    "La première chose à faire est de calculer la distance entre le point\n",
    "$\\textbf{p}$ avec tous les autres points. Ensuite trouver les $K$ points\n",
    "les plus proches de $\\textbf{p}$. C'est-à-dire les $K$ points dont la\n",
    "distance avec $\\textbf{p}$ est minimale. Les $K-$points plus proches de\n",
    "$\\textbf{p}$ dans l'échantillon d'apprentissage sont obtenus par:\n",
    "\n",
    "$$\\underset{\\mathbf{x}_i}{K-\\mbox{argmin}}\\  \\{d(\\textbf{p},\\mathbf{x}_i), i=1, \\dots, n\\}.$$\n",
    "\n",
    "Pour tout\n",
    "$i \\in \\{1, \\dots, n\\},  d_{p, i} := \\{ d(p, \\mathbf{x}_i), ~ i = 1, \\dots, n \\}$\n",
    "où $d$ est une fonction de distance. Et en suite la classe prédite de\n",
    "$\\textbf{p}$ notée $\\hat{\\textbf{y}}$ est la classe majoritairement\n",
    "représentée par les $k$ voisins.\n",
    "\n",
    "Les points similaires ou les points les plus proches sont sélectionnés\n",
    "en utilisant une fonction de distance telle que la distance\n",
    "euclidienne [\\[Euclidienne\\]](#Euclidienne){reference-type=\"eqref\"\n",
    "reference=\"Euclidienne\"}, la distance de\n",
    "Manhattan [\\[Manhattan\\]](#Manhattan){reference-type=\"eqref\"\n",
    "reference=\"Manhattan\"} et la distance de Minkowski\n",
    " [\\[Minkowski\\]](#Minkowski){reference-type=\"eqref\"\n",
    "reference=\"Minkowski\"}. On choisit la fonction de distance en fonction\n",
    "des types de données manipulées, par exemple dans le cas où les données\n",
    "sont quantitatives et du même type, c'est la distance euclidienne qui\n",
    "est utilisée.\n",
    "\n",
    "Les points les plus proches de $P$ sont trouvés en utilisant une\n",
    "fonction de distance telle que la distance Euclidienne, la distance de\n",
    "Minkowski et la distance de Manhattan.\n",
    "\n",
    "#### Algorithme\n",
    "\n",
    "Soient $\\mathcal{D}$ un échantillon d'apprentissage des observations\n",
    "$\\mathbf{x}_i$ relatives à une classe $y_i$\n",
    "$\\mathcal{D}=\\{(\\mathbf{x}_i, y_i), i=1, \\dots,n\\}$ et $\\textbf{p}$ une\n",
    "nouvelle observation dont la classe $\\hat{c}$ doit être prédite. **Les\n",
    "étapes de l'algorithme:** Ainsi, l'algorithme se présente comme suit:\n",
    "\n",
    "1.  Choisir le paramètre $K$, le nombre de voisins les plus proches;\n",
    "\n",
    "2.  Calculer la distance de la nouvelle observation $\\textbf{p}$ avec\n",
    "    tous les autres échantillons selon une fonction de distance choisie\n",
    "    $d(p, \\mathbf{x}_i);$\n",
    "\n",
    "3.  Sélectionner les $K$ plus proches voisins de $\\textbf{p}$;\n",
    "\n",
    "4.  Former la collection $K_c$ des étiquettes des $K$ plus proches\n",
    "    voisins de $\\textbf{p}$;\n",
    "\n",
    "5.  Et la classe de $\\textbf{p}$, $\\hat{c}$ est choisie d'après la\n",
    "    majorité des $K_c$ plus proches voisins, c'est-à-dire\n",
    "    $$\\hat{c}=\\mbox{Mode}(K_c)$$.\n",
    "\n",
    "6.  Répéter l'étape 2 à 5 pour chaque nouveau point à classifier.\n",
    "\n",
    "L'algorithme [\\[algorithme_knn\\]](#algorithme_knn){reference-type=\"ref\"\n",
    "reference=\"algorithme_knn\"} nous présente le pseudo-code de la méthode\n",
    "de plus proches voisins.\n",
    "\n",
    "::: {.algorithm}\n",
    "::: {.algorithmic}\n",
    "Un ensemble de données\n",
    "$\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\}, i = 1, \\dots,n$ Choisir une\n",
    "fonction de distance $d$ Choisir un nombre $K \\in \\mathbb{N}^*$ Pour une\n",
    "nouvelle observation $\\textbf{p}$ dont on veut prédire la classe\n",
    "$\\hat{c}$:      Calculer la distance $d(\\textbf{p},\\mathbf{x}_i)$\n",
    "     Retenir les $K$ observations proches de $\\textbf{p}$:\n",
    "$\\underset{\\mathbf{x}_i}{K-\\arg \\min}\\  \\{d(\\textbf{p},\\mathbf{x}_i), i=1, \\dots, n\\}$\n",
    "     Prendre les valeurs $\\displaystyle y_{k}$ des $K$ observations\n",
    "retenues:           Si on effectue une régression:\n",
    "$\\hat{c}= \\frac{1}{K}\\sum_{k=1}^{K} y_k$ (la moyenne ou la médiane des\n",
    "$y_k$ retenues)           Si on effectue une classification : Calculer\n",
    "le mode des $y_k$ retenues      Retourner $\\hat{c}$, la valeur qui a été\n",
    "prédite par $K$-NN pour l'observation $\\textbf{p}$.\n",
    ":::\n",
    ":::\n",
    "\n",
    "#### Comment choisir la valeur de $K$ ?\n",
    "\n",
    "- En générale, le choix de la valeur de $K \\in \\mathbb{N}^{*}$ dépend\n",
    "  du jeu de données. Pour la classification binaire (en deux classes)\n",
    "  par exemple il est préférable de choisir la valeur $K$ impaire pour\n",
    "  éviter les votes égalitaires. Historiquement, la valeur optimale de\n",
    "  $K$ pour la plupart de données est choisie entre 3 et 10\n",
    "  [@shalev2014understanding].\n",
    "\n",
    "- Une optimale valeur de $K$ peut être sélectionnée par diverses\n",
    "  techniques heuristiques dont la **validation-croisée** (que nous\n",
    "  allons expliquer ci-dessous).\n",
    "\n",
    "- Notons que, si l'algorithme est utilisé pour la régression, c'est la\n",
    "  moyenne (ou la médiane) des variables $\\mathbf{y}$ des $K$ plus\n",
    "  proches observations qui sera utilisée pour la prédiction. Et dans\n",
    "  le cas de la classification, c'est le mode des variables\n",
    "  $\\mathbf{y}$ des $K$ plus proches observations qui servira pour la\n",
    "  prédiction.\n",
    "\n",
    "**Validation-croisée (Cross-Validation)**\n",
    "\n",
    "La Validation-croisée (_Cross-validation_) est une méthode très\n",
    "populaire utilisée pour estimer la performance d'un algorithme. C'est\n",
    "une méthode statistique souvent utilisée dans des procédures\n",
    "d'estimation et aussi pour la sélection de modèles [@chen2019mehryar].\n",
    "\n",
    "Son principe est le suivant :\n",
    "\n",
    "- séparer les données en données en deux échantillon (apprentissage et\n",
    "  validation);\n",
    "\n",
    "- construire l'estimateur sur l'échantillon d'apprentissage et\n",
    "  utiliser l'échantillon de validation pour évaluer l'erreur de\n",
    "  prédiction;\n",
    "\n",
    "- Répéter plusieurs fois le processus et enfin faire une moyenne des\n",
    "  erreurs de prédiction obtenues.\n",
    "\n",
    "C'est une technique très utilisée pour le choix de meilleurs paramètres\n",
    "et hyperparamètres d'un modèle, par exemple pour le choix de la\n",
    "meilleure valeur de $K$ dans l'algorithme de plus proches voisins\n",
    "($K$-NN).\n",
    "\n",
    "On distingue les variantes suivantes de la technique de\n",
    "validation-croisée:\n",
    "\n",
    "- $K$-fold cross-validation : Partitionnement des données en $K$\n",
    "  sous-ensembles. Chaque sous-ensemble sert à tour de rôle\n",
    "  d'échantillon de validation et le reste de sous-ensembles\n",
    "  d'échantillon d'apprentissage. En pratique la valeur de $K$ varie\n",
    "  entre $5$ et $10$.\n",
    "\n",
    "- Leave-one-out cross-validation: qui signifie de laisser à tour de\n",
    "  rôle une observation comme échantillon de validation et le reste des\n",
    "  données comme échantillon d'apprentissage. C'est un $n$-fold\n",
    "  validation-croisée avec $n$, le nombre total d'observations.\n",
    "\n",
    "- Leave-$q$-out qui signifie de laisser à tour de rôle $q$\n",
    "  observations comme échantillon de validation et le reste des données\n",
    "  comme échantillon d'apprentissage. C'est une $\\lceil\n",
    "    \\frac{n}{q}\\rceil$-fold validation-croisée.\n",
    "\n",
    "D'une manière générale, la procédure de partitionnement des données se\n",
    "présente souvent comme suit:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\underbrace{Apprentissage }_{70\\%} +\n",
    "    \\underbrace{Validation}_{10\\%}+\n",
    "    \\underbrace{Test}_{20\\%}\\end{aligned}\n",
    "$$\n",
    "\n",
    "- Les données d'apprentissage permettent de trouver un estimateur.\n",
    "\n",
    "- Les données de validation nous permettent de trouver les meilleurs\n",
    "  paramètres du modèle.\n",
    "\n",
    "- Les données test permettent de calculer l'erreur de prédiction\n",
    "  finale. Notons que cette méthode de validation-croisée est utilisée\n",
    "  pour tous types d'algorithme d'apprentissage.\n",
    "\n",
    "#### Les avantages de l'algorithme de $K$-NN\n",
    "\n",
    "- Il est simple, facile à interpréter.\n",
    "\n",
    "- Il n'existe pas de phase d'apprentissage proprement dite comme c'est\n",
    "  le cas pour les autres algorithmes, c'est pour cela qu'on le\n",
    "  classifie dans le _Lazy Learning._\n",
    "\n",
    "- Offre des performances très intéressantes lorsque le volume de\n",
    "  données d'apprentissage est trop large.\n",
    "\n",
    "- Le temps d'exécution est minimum par rapport à d'autres algorithmes\n",
    "  de classification.\n",
    "\n",
    "- Il peut être utilisé pour classification et régression.\n",
    "\n",
    "- Il ne fait pas d'hypothèse (linéaire, affines,..) sur les données.\n",
    "\n",
    "#### Les limitations de l'algorithme de $K$-NN\n",
    "\n",
    "- L'algorithme a plus besoin de mémoire car l'ensemble des données\n",
    "  doivent être garder dans cette dernière pour pouvoir effectuer la\n",
    "  prédiction d'une nouvelle observation à chaque fois.\n",
    "\n",
    "- Sensibles aux attributs non pertinents et non corrélés.\n",
    "\n",
    "- L'étape de la prédiction peur être lente dû au calcul de distance de\n",
    "  chaque nouvelle observation avec les jeux de données en entier à\n",
    "  chaque prédiction.\n",
    "\n",
    "- Le choix de la fonction de distance ainsi que le nombre de voisins\n",
    "  $K$ peut ne pas être évident. C'est ainsi qu'il faut essayer\n",
    "  plusieurs combinaisons(en utilisant la méthode de\n",
    "  validation-croisée) pour avoir un bon résultat.\n",
    "\n",
    "#### Exemple pratique\n",
    "\n",
    "Ci-dessous, nous allons prendre un exemple simple pour comprendre\n",
    "l'intuition derrière l'algorithme de $K$-NN. Considérons le tableau de\n",
    "données ci-dessous qui contient la taille (feet), l'âge (année) et le\n",
    "poids(en kilogramme) de $10$ personnes où ID représente l'identifiant de\n",
    "chaque personne dans le tableau. Comme vous le remarquez le poids du ID\n",
    "$11$ est manquant. Nous allons appliquer l'algorithme de $K$-NN pour\n",
    "prédire le poids de la personne ID 11.\n",
    "\n",
    "::: {#tab:rrr}\n",
    "   **ID**   **Taille**   **Âge**   **Poids**\n",
    "  -------- ------------ --------- -----------\n",
    "     1          5          45         77\n",
    "     2         5.11        26         47\n",
    "     3         5.6         30         55\n",
    "     4         5.9         34         59\n",
    "     5         4.8         40         72\n",
    "     6         5.8         36         60\n",
    "     7         5.3         19         40\n",
    "     8         5.8         28         60\n",
    "     9         5.5         23         45\n",
    "     10        5.6         32         58\n",
    "     11        5.5         38          ?\n",
    "\n",
    "  : Données pour l'illustration\n",
    ":::\n",
    "\n",
    "[\\[tab:rrr\\]]{#tab:rrr label=\"tab:rrr\"}\n",
    "\n",
    "Nous pouvons représenter graphiquement les données du tableau\n",
    "[1.1](#tab:rrr){reference-type=\"ref\" reference=\"tab:rrr\"} en se basant\n",
    "sur la taille et l'âge.\n",
    "\n",
    "![](images/KNN_new.png){#fig:knnnew width=\"0.6\\\\linewidth\"}\n",
    "\n",
    "Comme nous le remarquons, le point rouge (ID 11) est notre nouvelle\n",
    "observation dont nous voulons prédire la classe dans laquelle il\n",
    "appartient.\n",
    "\n",
    "**Étape 1:** Commençons par choisir le nombre des voisins les plus\n",
    "proche. Pour notre cas prenons $K=5$.\n",
    "\n",
    "**Étape 2:** Calculer la distance entre le nouveau point (rouge) avec\n",
    "tous les autres points\n",
    "\n",
    "![La distance euclidienne entre nouvelle observation et tous les autres\n",
    "points](images/KNN_dist.png){#fig:step2knn width=\"0.6\\\\linewidth\"}\n",
    "\n",
    "**Étape 3:** Sélectionner les $5$ plus proches voisins.\n",
    "\n",
    "![Sélection de $5$ plus proches\n",
    "voisins](images/KNN_sel.png){#fig:selectknn width=\"0.6\\\\linewidth\"}\n",
    "\n",
    "**Étape 4:** Pour la valeur de $K=5$, les points les plus proches sont\n",
    "$1,\\ 4,\\ 5,\\ 6\\text{ et } 10.$\n",
    "\n",
    "**Étape 5:** Ainsi, comme la classe des points $4,\\ 6$ et $10$ est\n",
    "majoritaire donc le point $11$ se classifie dans cette classe. Et comme\n",
    "c'est un cas de la régression, la prédiction pour ID11 est la moyenne de\n",
    "ces 5 voisins les plus proches c'est-à-dire\n",
    "$(77+59+72+60+58)/5=65.2\\ Kg$. Ainsi le poids prédit pour ID11 est\n",
    "$65.2\\ Kg$.\n",
    "\n",
    "### L'algorithme du Perceptron\n",
    "\n",
    "L'algorithme de perceptron est un algorithme d'apprentissage supervisé\n",
    "utilisé pour la classification binaire (c'est-à-dire séparant deux\n",
    "classes). C'est l'un des tout premier algorithme d'apprentissage\n",
    "supervisé et de réseau de neurones artificiels le plus simple. Le terme\n",
    "vient de l'unité de base dans un\n",
    "[neurone](https://fr.wikipedia.org/wiki/R%C3%A9seau_de_neurones_artificiels#Perceptron_2)\n",
    "qui s'appelle *perceptron*.\n",
    "\n",
    "C'est un type de classification linéaire, c'est-à-dire que les données\n",
    "d'apprentissage sont séparées par une droite classées dans des\n",
    "catégories correspondantes de telle sorte que si la classification à\n",
    "deux catégories est appliquée, toutes les données sont rangées dans ces\n",
    "deux catégories. Dans ce cas on cherche à trouver un hyperplan qui\n",
    "sépare correctement les données en deux catégories. Comme nous le voyons\n",
    "dans la figure [1.12](#fig:perceptron){reference-type=\"ref\"\n",
    "reference=\"fig:perceptron\"} ci-dessous.\n",
    "\n",
    "![L'algorithme du perceptron](images/Percep.png \"fig:\"){#fig:perceptron\n",
    "width=\"5cm\"} ![L'algorithme du\n",
    "perceptron](images/decision limite.png \"fig:\"){#fig:perceptron\n",
    "width=\"5cm\"}\n",
    "\n",
    "L'idée générale de l'algorithme du perceptron est d'initialiser le\n",
    "vecteur de poids réels $\\mathbf{w} \\in \\mathbb{R}^d$ au vecteur nul ou à\n",
    "une variable aléatoire, itérer un nombre de fois jusqu'à la convergence\n",
    "sur les données d'apprentissage.\n",
    "\n",
    "Soient $\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\}^{n}_{i=1}$, un ensemble de\n",
    "données où $\\mathbf{x}_i \\in \\mathbb{R}^d$ est le vecteur d'entrées de\n",
    "dimension $d$ et l'étiquette $y_i \\in \\{-1,1\\}$;\n",
    "$\\mathbf{w} \\in \\mathbb{R}^d$ un vecteur poids de dimension $d$.\n",
    "\n",
    "L'objectif est de trouver un hyperplan $\\mathbf{w}.\\mathbf{x} + b=0$ qui\n",
    "sépare les deux classes. Le terme $b$ est l'intercepte appelé aussi\n",
    "\\\"*bias term*\\\" et $\\mathbf{w}\\cdot \\mathbf{x}$ est le produit scalaire\n",
    "défini par\n",
    "$\\langle \\mathbf{w},\\mathbf{x} \\rangle := \\sum_{s=1}^{d} w_{s} \\mathbf{x}_{s}$.\n",
    "\n",
    "C'est-à-dire apprendre le vecteur $\\mathbf{w}$ tel que:\n",
    "$$\\begin{aligned}\n",
    "  \\mathbf{y}& = \\operatorname{signe}\\left(\\mathbf{w}\\cdot \\mathbf{x} +b\\right) \n",
    "  \\end{aligned}$$ $$\\begin{aligned}\n",
    "  \\text{Si } \\mathbf{w}\\cdot \\mathbf{x} +b>0 \\text{ alors } \\operatorname{sgn}(\\mathbf{w}\\cdot \\mathbf{x} +b) =+1, \\text{ pour tout } \\mathbf{x} \\text{ appartenant \\`a la classe positive.}\\\\\n",
    "  \\text{Si } \\mathbf{w}\\cdot \\mathbf{x} + b \\leq 0 \\text{ alors } \\operatorname{sgn}(\\mathbf{w}\\cdot \\mathbf{x} +b) = -1, \\text{ pour tout } \\mathbf{x} \\text{ appartenant \\`a la classe négative.}\n",
    "  \\end{aligned}$$\n",
    "\n",
    "  #### Algorithme\n",
    "\n",
    "Soient les données d'apprentissage\n",
    "$\\mathcal{D} = \\{(\\mathbf{x}_1, y_1), \\dots, (\\mathbf{x}_n, y_n)\\}$ où\n",
    "$\\mathbf{x}_i \\in \\mathbb{R}^d$, $y_i \\in \\{-1,1\\}$ et $T$ le nombre\n",
    "d'itérations. L'algorithme se présente comme suit:\n",
    "\n",
    "::: {.algorithm}\n",
    "::: {.algorithmic}\n",
    "Initialiser le vecteur $\\mathbf{w} \\leftarrow 0$ **Pour** itération de 1\n",
    "à T: **   Pour** chaque exemple $(\\mathbf{x}_i, y_i) \\in \\mathcal{D}:$\n",
    "      Calculer la prédiction\n",
    "$\\hat{y_i} = \\operatorname{signe }( \\mathbf{w}. \\mathbf{x}_i +b )$\n",
    "**      Si** $\\hat{y_i} \\neq y_i$ **alors**          Ajuster\n",
    "$\\mathbf{w} :$ par\n",
    "         $\\mathbf{w_{t+1}} \\leftarrow \\mathbf{w_t}+\\mathbf{x}_i$ si\n",
    "$y_i$ est positive\n",
    "         $\\mathbf{w_{t+1}} \\leftarrow \\mathbf{w_t}-\\mathbf{x}_i$ si\n",
    "$y_i$ est négative       **Fin si**    **Fin pour** **Fin pour**\n",
    ":::\n",
    ":::\n",
    "\n",
    "L'avantage de l'algorithme de perceptron est sa simplicité et son\n",
    "efficacité de séparer linéairement les données d'apprentissage.\n",
    "Néanmoins, tous les hyperplans qui séparent les données sont\n",
    "équivalents.\n",
    "\n",
    "L'algorithme ne peut séparer et converger vers la solution uniquement\n",
    "que si les données d'apprentissage sont linéairement séparables. Aussi,\n",
    "il n'est pas efficace quand il y a beaucoup d'attributs.\n",
    "\n",
    "### La Régression Logistique\n",
    "\n",
    "La régression logistique est une méthode de classification simple mais\n",
    "puissante, pour les données binaires, et elle peut facilement être\n",
    "étendue à plusieurs classes. Considérons d'abord le modèle de régression\n",
    "le plus simple, correspondant à celui que nous avons vu précédemment,\n",
    "pour effectuer la classification. Nous le trouverons bientôt totalement\n",
    "insuffisant pour ce que nous voulons réaliser et il sera instructif de\n",
    "voir exactement pourquoi. Le modèle de la régression linéaire comme\n",
    "défini dans l'équation [\\[reg_lin\\]](#reg_lin){reference-type=\"eqref\"\n",
    "reference=\"reg_lin\"}, peut se réécrire comme:\n",
    "$$h_{\\boldsymbol{\\theta}}(\\mathbf{X})=  \\mathbf{X}\\boldsymbol{\\theta},$$\n",
    "\n",
    "où $\\mathbf{X}$ est une matrice de taille $n\\times d$ et\n",
    "$\\boldsymbol{\\theta} \\in \\mathbb{R}^{d}$.\n",
    "\n",
    "Comme dans de nombreux problèmes d'estimation de paramètres,\n",
    "$\\boldsymbol{\\theta}$ est trouvé en minimisant certaines fonctions de\n",
    "pertes qui capturent à quel point notre prédiction est proche de la\n",
    "valeur réelle. Quand nous faisons des hypothèses sur la distribution des\n",
    "données, la fonction de perte est souvent en termes de vraisemblance des\n",
    "données. Cela signifie que le $\\boldsymbol{\\theta}$ optimal est celui\n",
    "pour lequel les données observées ont la probabilité la plus élevée. Par\n",
    "exemple, la régression linéaire suppose généralement que la variable\n",
    "dépendante est normalement distribuée autour de la moyenne\n",
    "$h_{\\boldsymbol{\\theta}}(\\mathbf{x})$. Il peut être montré que la\n",
    "solution du maximum de vraisemblance est le $\\boldsymbol{\\theta}$ qui\n",
    "minimise la somme des erreurs quadratiques (la différence entre les\n",
    "valeurs prédites et les valeurs correctes). Si nous essayons d'utiliser\n",
    "la régression linéaire pour un problème de classification (prenons\n",
    "l'exemple d'une classification binaire) une méthode simple serait de\n",
    "grouper les données de telle sorte que: $$y= \n",
    "\\begin{cases}\n",
    "1,& \\text{si } \\boldsymbol{\\theta}^{T}\\mathbf{x} > 0 \\quad (\\mathbf{x}\\in \\mathbb{R}^{d}) \\\\\n",
    "0,& \\text{sinon}\n",
    "\\end{cases}$$ Ceci est illustré par la figure\n",
    "[1.13](#Figure1){reference-type=\"ref\" reference=\"Figure1\"}.\n",
    "\n",
    "![Régression linéaire dans le cas d'une classification\n",
    "binaire](images/linear_for_classi.png){#Figure1 width=\"8cm\"\n",
    "height=\"8cm\"}\n",
    "\n",
    "#### La régression logistique binaire\n",
    "\n",
    "La régression logistique ordinaire ou régression logistique binaire vise\n",
    "à expliquer une variable d'intérêt binaire (c'est-à-dire de type « oui /\n",
    "non » ou « vrai / faux »). Les variables explicatives qui seront\n",
    "introduites dans le modèle peuvent être quantitatives (l'âge, la taille,\n",
    "etc) ou qualitatives (le genre par exemple).\n",
    "\n",
    "**Exemple**\n",
    "\n",
    "Dans cet exemple, la variable explicative $x$ est une matrice de\n",
    "vecteurs colonnes $\\mathbf{x}_1, \\mathbf{x}_2$ où $\\mathbf{x}_1$ est le\n",
    "vecteur 'apprendre' qui représente le nombre d'heures d'étude de\n",
    "l'étudiant, et $\\mathbf{x}_2$ est le nombre d'heures pendant lesquelles\n",
    "l'étudiant dort. L'objectif est de prédire si l'étudiant va réussir à\n",
    "l'examen ou non, respectivement représentée par les classes 1 et 0.\n",
    "\n",
    "::: {.center}\n",
    "   Apprendre   Dormir   Réussir  \n",
    "  ----------- -------- --------- --\n",
    "     4.85       9.63       1     \n",
    "     8.62       3.23       0     \n",
    "     5.43       8.23       1     \n",
    "     9.21       6.34       0     \n",
    ":::\n",
    "\n",
    "Comme dans le cas de la régression linéaire, on suppose que les données\n",
    "suivent une fonction linéaire de la forme:\n",
    "$$\\mathbf{y}= \\boldsymbol{\\theta}^T\\mathbf{x}.$$ $\\mathbf{y}$ représente\n",
    "la variable à expliquer, $\\mathbf{x}$ est la variable explicative et\n",
    "$\\boldsymbol{\\theta}$ un paramètre. Comme nous l'avons vu, la variable\n",
    "$\\mathbf{y}$ est une variable continue. Pour utiliser cette technique\n",
    "dans le cas d'une variable discrète (ici binaire), supposons que $p$ est\n",
    "la probabilité qu'un événement se réalise; alors $1-p$ est la\n",
    "probabilité de l'évènement contraire. La variable aléatoire $\\mathbf{y}$\n",
    "qui prend les valeurs 'oui' ou 'non' (1,0 en langage machine) suit la\n",
    "loi de Bernoulli. On définit ce qu'on appelle la transformation logit\n",
    "donnée par l'équation suivante:\n",
    "$$\\log\\left(\\frac{p}{1-p}\\right)=\\boldsymbol{\\theta}^T\\mathbf{x} .$$\n",
    "Cette transformation donne la relation entre la probabilité qu'un\n",
    "évenment se réalise et la combinaison linéaire des variables. Le rapport\n",
    "$\\frac{p}{1-p}$ est appelé le Rapport de Côte (RC). En appliquant\n",
    "l'exponentielle sur cette relation on obtient:\n",
    "$$\\frac{p}{1-p} =  e^{\\boldsymbol{\\theta}^T\\mathbf{x}}.$$ Ce qui\n",
    "implique: $$\\begin{aligned}\n",
    "p &=\\frac{e^{\\boldsymbol{\\theta}^T\\mathbf{x}}}{1+e^{\\boldsymbol{\\theta}^T\\mathbf{x}}}\\nonumber\\\\\n",
    "%&=\\frac{1}{\\frac{1}{e^{X\\boldsymbol{\\theta}+1}}}\\nonumber\\\\\n",
    "&=\\frac{1}{1+e^{-\\boldsymbol{\\theta}^T\\mathbf{x}}}\\end{aligned}$$\n",
    "\n",
    "Avec $z= \\boldsymbol{\\theta}^T\\mathbf{x}$, la fonction $\\sigma$ définie\n",
    "par $\\displaystyle \\sigma(z)=\\frac{1}{1+e^{-z}}$ est appelée la fonction\n",
    "Sigmoïde ou logistique. Dans les lignes qui suivent, nous allons donner\n",
    "certaines de ses propriétés.\n",
    "\n",
    "### La fonction Sigmoïde et ses propriétés\n",
    "\n",
    "Elle est définie par: $$\\sigma(z)=\\dfrac{1}{1+e^{-z}},\n",
    "    $$\n",
    "\n",
    "La représentation graphique de la fonction Sigmoïde est donnée par la\n",
    "figure [1.14](#sigmoid){reference-type=\"ref\" reference=\"sigmoid\"}.\n",
    "\n",
    "![La fonction Sigmoïde](images/logistic2.png){#sigmoid width=\"13cm\"\n",
    "height=\"10cm\"}\n",
    "\n",
    "Une qualité importante de cette fonction est qu'elle transforme tous les\n",
    "nombres réels sur la plage $[0, 1]$. En régression logistique, cette\n",
    "transformation $\\sigma (z)$ nous permet d'avoir une vue probabiliste qui\n",
    "est d'une importance cruciale pour la classification. Avec cette\n",
    "fonction, les nombres positifs deviennent des probabilités élevées; les\n",
    "nombres négatifs deviennent de faible probabilité.\n",
    "\n",
    "Comme vous l'avez sûrement remarqué, l'algorithme de régression linéaire\n",
    "repose sur l'obtention d'un paramètre $\\boldsymbol{\\theta}^{*}$ dit\n",
    "optimal. Dans la section suivante nous allons discuter sur le choix et\n",
    "l'obtention de la valeur $\\boldsymbol{\\theta}^{*}$.\n",
    "\n",
    "#### Estimation du maximum de vraisemblance\n",
    "\n",
    "Pour choisir la valeur du paramètre $\\boldsymbol{\\theta}$, on utilise la\n",
    "méthode du maximum de vraisemblance. La variable à expliquer\n",
    "$\\mathbf{y}$ est une variable binaire, i.e $\\mathbf{y}\\in \\{0,1\\}$ et la\n",
    "fonction Sigmoïde nous permet de projeter les résultats dans\n",
    "l'intervalle $[0, 1]$. Plus précisément, pour un $z$ considéré, on\n",
    "choisit $\\sigma (z) \\in [0,1]$ comme étant un paramètre d'une loi de\n",
    "Bernoulli et ainsi, on a pour tout $i=1, \\dots, n$: $$\\begin{aligned}\n",
    "\\mathbb{P}(Y=y_{i})&=\\left(\\sigma(z)\\right)^{y_{i}}\\left(1-\\sigma(z)\\right)^{1-y_{i}}\\\\\n",
    "&=\\left(\\sigma(\\boldsymbol{\\theta}^T\\mathbf{x}_i)\\right)^{y_{i}} \\left (1-\\sigma(\\boldsymbol{\\theta}^T\\mathbf{x}_i)\\right)^{1-y_{i}}\\end{aligned}$$\n",
    "Par suite, on peut exprimer la vraisemblance:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\ell(\\boldsymbol{\\theta})&=\\prod_  {i=1}^{n}\\mathbb{P}\\left(Y=y_{i}\\right)\\end{aligned}$$\n",
    "En appliquant la fonction logarithme, on obtient le\n",
    "logarithme-vraisemblance donnée par l'expression suivante:\n",
    "$$\\begin{aligned}\n",
    "    \\log( \\ell(\\boldsymbol{\\theta}))\\equiv L(\\boldsymbol{\\theta})=\\sum_{i=1}^{n}y_{i}\\log\\sigma\\left(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i\\right) + \\left(1-y_{i}\\right)\\log\\left(1-\\sigma(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i)\\right)\\end{aligned}$$\n",
    "\n",
    "Notre objective est de trouver le paramètre $\\boldsymbol{\\theta}$ qui\n",
    "maximise la vraisemblance: $$\\begin{aligned}\n",
    " \\max_{\\boldsymbol{\\theta}}\n",
    " L(\\boldsymbol{\\theta}) = \\max_{\\boldsymbol{\\theta}}\\sum_{i=1}^{n}y_{i}\\log\\sigma \\left(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i \\right) + \\left(1-y_{i}\\right)\\log \\left(1-\\sigma(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i)\\right)   \\end{aligned}$$\n",
    "\n",
    "En générale, pour trouver l'estimation du maximum de vraisemblance, nous\n",
    "dérivons d'abord la $\\log$-vraisemblance par rapport à\n",
    "$\\boldsymbol{\\theta}$. Pour commencer, prenons la dérivée par rapport à\n",
    "une composante de $\\boldsymbol{\\theta}$, disons $\\theta^j$\n",
    "$$\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial \\theta^j}L(\\boldsymbol{\\theta})\n",
    "&=\\left[ y_i\\frac{1}{\\sigma(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i)}-(1-y_i)\\frac{1}{1-\\sigma(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i)}\\right]\\sigma(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i)(1-\\sigma(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i))(\\frac{\\partial}{\\partial \\theta^j}\\boldsymbol{\\theta}^{T}\\mathbf{x}_i)\\\\\n",
    "&=\\left[y_i(1-\\sigma(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i))-(1-y_{i})\\sigma(\\boldsymbol{\\theta}^{T}\\mathbf{x}_i)\\right]\\mathbf{x}_i^{j}\\\\\n",
    "&=\\left(y_{i}-\\sigma(\\boldsymbol{\\theta}^{T} \\mathbf{x}_i)\\right)\\mathbf{x}_i^{j}\\end{aligned}$$\n",
    "Une méthode classique de trouver le $\\boldsymbol{\\theta}$ optimal est de\n",
    "poser la dérivée\n",
    "$\\displaystyle \\frac{\\partial}{\\partial \\theta^j}L(\\boldsymbol{\\theta})=0$\n",
    "pour tout $j$ et trouver la valeur exacte de $\\boldsymbol{\\theta}$ qui\n",
    "maximise la vraisemblance. Cependant, la solution exacte n'est pas\n",
    "toujours facile à calculer à cause du fait que c'est une équation\n",
    "transcendantale (il n'y a pas de solution analytique). Par conséquent,\n",
    "la technique souvent utilisée pour résoudre ce problème est la méthode\n",
    "de la descente de gradient [1.1.1.2](#GD){reference-type=\"ref\"\n",
    "reference=\"GD\"}.\n",
    "\n",
    "Ainsi en utilisant la technique de la descente de gradient, le paramètre\n",
    "$\\theta^j$ sera mis à jour par la formule suivante, pour chaque\n",
    "itération:\n",
    "\n",
    "$$\\theta^j = \\theta^j + \\gamma . \\frac{\\partial}{\\partial \\theta^j}L(\\boldsymbol{\\theta}).$$\n",
    "\n",
    "Le paramètre $\\gamma$ est appelé taux d'apprentissage. Le paramètre\n",
    "$\\boldsymbol{\\theta}^{*}$ obtenu à la sortie de cet algorithme maximise\n",
    "la log-vraisemblance.\n",
    "\n",
    "Ainsi nous considérons un seuil 0.5 et regroupons les données comme\n",
    "suit: $$\\hat{y}= \n",
    "\\begin{cases}\n",
    "1,& \\text{si } \\sigma(\\boldsymbol{\\theta}^{*T}\\mathbf{x}) > 0.5 \\\\\n",
    "0,& \\text{sinon}\n",
    "\\end{cases}$$\n",
    "\n",
    "#### Cas pratique\n",
    "\n",
    "### Régression logistique multinomiale\n",
    "\n",
    "La régression logistique multinomiale est une forme généralisée de la\n",
    "régression logistique binaire utilisée pour estimer la probabilité quand\n",
    "le nombre de classe $C$ est supérieur à deux. Prenons l'exemple de\n",
    "reconnaissance de chiffres à partir de leur image. Cette tâche consiste\n",
    "à identifier une image comme l'un des éléments de l'ensemble\n",
    "$\\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\}$. Dans ce cas, la fonction\n",
    "[^1]Sigmoïde utilisée dans le cas binaire est remplacée par la\n",
    "[^2]*fonction Softmax*.\n",
    "\n",
    "### La fonction Softmax et ses propriétés\n",
    "\n",
    "La régression logistique multinomiale utilise une *fonction Softmax*\n",
    "pour modéliser la relation entre les variables explicatives et les\n",
    "probabilités de chaque classe. Elle prédit la classe qui a la\n",
    "probabilité la plus élevée parmi toutes les classes.\n",
    "\n",
    "La fonction $\\operatorname{Softmax}$ est définie par:\n",
    "\n",
    "$$\n",
    "\\operatorname{Softmax}(z)_i=\\dfrac{e^{z_i}} {\\sum_{j=1}^{C} e^{z_{j}}}, \\quad i=1,\\cdots, C.\n",
    "u$$\n",
    "\n",
    "où $C$ est le nombre de classes.\n",
    "\n",
    "Cette fonction $\\operatorname{Softmax}$ prend comme entrée $\\mathbf{z}$\n",
    "qui est un vecteur de dimension $n$ et produit $\\mathbf{\\hat{y}}$ un\n",
    "vecteur de même dimension de valeurs réelles entre $0$ et $1$.\n",
    "\n",
    "Toutes les valeurs $z_{i}$ sont les éléments du vecteur d'entrée et\n",
    "peuvent prendre n'importe quelle valeur réelle. Le dénominateur de la\n",
    "formule [\\[soft\\]](#soft){reference-type=\"ref\" reference=\"soft\"} est le\n",
    "terme de normalisation qui garantit que toutes les valeurs de sortie de\n",
    "la fonction totaliseront $1$, constituant ainsi une distribution de\n",
    "probabilité valide.\n",
    "\n",
    "On peut écrire la probabilité de la classe $c$ pour $c=1,\\cdots,C$\n",
    "sachant $\\mathbf{x}$ comme:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "\\mathbb{P}(y=1|\\mathbf{x}) \\\\           \n",
    "\\vdots \\\\\n",
    "\\mathbb{P}(y=C|\\mathbf{x}) \n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\operatorname{Softmax}(\\mathbf{x})_{1} \\\\\n",
    "\\vdots \\\\\n",
    "\\operatorname{Softmax}(\\mathbf{x})_{C}\n",
    "\\end{bmatrix}=\n",
    "\\dfrac{1}{\\sum_{j=1}^{C}e^{\\boldsymbol{\\theta}^T \\mathbf{x}_{j}}} \n",
    "\\begin{bmatrix}\n",
    "e^{\\boldsymbol{\\theta}^T \\mathbf{x}_1}\\\\\n",
    "\\vdots \\\\\n",
    "e^{\\boldsymbol{\\theta}^T \\mathbf{x}_{C}}\n",
    "\\end{bmatrix}\\end{aligned}$$\n",
    "\n",
    "### Estimation du maximum de vraisemblance\n",
    "\n",
    "De la même façon que dans le cas de la régression binaire, nous suivrons\n",
    "la même procédure pour déterminer le $\\boldsymbol{\\theta}$ qui maximise\n",
    "la vraisemblance. $$\n",
    "\\ell(\\boldsymbol{\\theta})= \\prod_{i=1}^{n}\\mathbb{P}(y_{i}|\\mathbf{x};\\boldsymbol{\\theta}).$$\n",
    "\n",
    "L'équation [\\[lv\\]](#lv){reference-type=\"eqref\" reference=\"lv\"} suppose\n",
    "que les instances de données ont été générées indépendamment. Ainsi, en\n",
    "appliquant le logarithme sur [\\[lv\\]](#lv){reference-type=\"eqref\"\n",
    "reference=\"lv\"}, nous obtenons: $$\\begin{aligned}\n",
    "    L(\\boldsymbol{\\theta})&=\\sum_{j=1}^{n}\\sum_{i=1}^{C} \\log\\left[\\left(\\dfrac{e^{\\boldsymbol{\\theta}_{i}^T \\mathbf{x}_{j}}} {\\sum_{k=1}^{C} e^{\\boldsymbol{\\theta}_{k}^T \\mathbf{x}_{j}}}\\right)^{y_{j}}\\right]\\\\\n",
    "    &=\\sum_{j=1}^{n}\\sum_{i=1}^{C}y_{j}\\log\\left(\\dfrac{e^{\\boldsymbol{\\theta}^{T}_i \\mathbf{x}_{j}}} {\\displaystyle\\sum_{k=1}^{C} e^{\\boldsymbol{\\theta}^{T}_i \\mathbf{x}_{j}}}\\right).\\end{aligned}$$\n",
    "Donc maximiser la $\\operatorname{log-vraisemblance}$ équivaut à\n",
    "minimiser l'opposé de la $\\operatorname{log-vraisemblance}$ donnée par\n",
    "l'expression suivante :\n",
    "\n",
    "$$L(\\boldsymbol{\\theta})= -\\sum_{j=1}^{n}\\sum_{i=1}^{C}y_{j}\\log\\left(\\dfrac{e^{\\boldsymbol{\\theta}_{i}^T \\mathbf{x}_{j}}} {\\sum_{k=1}^{C} e^{\\boldsymbol{\\theta}^{T}_k \\mathbf{x}_{j}}}\\right)\n",
    "  =- \\sum_{j=1}^{n}\\sum_{i=1}^{C}y_{j}\\left[\\log\\left(e^{\\boldsymbol{\\theta}_{i}^T \\mathbf{x}_{j}} \\right) - \\log\\left( \\displaystyle\\sum_{k=1}^{C} e^{\\boldsymbol{\\theta}_{k}^T \\mathbf{x}_{j}} \\right)\\right].$$\n",
    "\n",
    "Cet opposé de la $\\operatorname{log-vraisemblance}$ est aussi connu sous\n",
    "le nom de **l'entropie de Shannon (cross-entropy)** qui est la fonction\n",
    "de perte dans ce cas. Pour trouver le $\\boldsymbol{\\theta}$ qui minimise\n",
    "cette fonction de perte, on suit la même procédure que dans le cas de la\n",
    "régression logistique, c'est-à-dire trouver la dérivée de la fonction de\n",
    "perte et appliquer l'algorithme de la descente de gradient.\n",
    "\n",
    "En Calculant la dérivée de la fonction de perte par rapport à\n",
    "$\\boldsymbol{\\theta}_{j}$ on a:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{j}}L(\\boldsymbol{\\theta})=-\\sum_{i=1}^{n}y_{i}\\mathbf{x}_i + \\sum_{i=1}^{n}\n",
    "\\dfrac{1}{{\\sum_{k=1}^{C}e^{\\boldsymbol{\\theta}_{k}^T \\mathbf{x}_i}}}e^{\\boldsymbol{\\theta}_{j}^T\\mathbf{x}_i}\\mathbf{x}_i$$\n",
    "\n",
    "Maintenant on utilise l'algorithme de la descente de gradient durant le\n",
    "processus d'entraînement pour obtenir le $\\boldsymbol{\\theta}$ optimal.\n",
    "À chaque itération, on met à jour chacun des paramètres\n",
    "$\\boldsymbol{\\theta}_j$ par la formule suivante:\n",
    "\n",
    "$$\\boldsymbol{\\theta}_{j} = \\boldsymbol{\\theta}_{j} - \\gamma\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{j}}L(\\boldsymbol{\\theta}).$$\n",
    "A la sortie de cette algorithme nous obtenons le paramètre optimal\n",
    "$\\boldsymbol{\\theta}^{*}$. Ainsi, le vecteur $\\mathbf{\\hat{y}}$ prédit\n",
    "est donné par:\n",
    "\n",
    "$$\\mathbf{\\hat{y}}= \\operatorname{argmax }~\\operatorname{softmax}(\\boldsymbol{\\theta}^{\\star} \\mathbf{x}_{test}).$$\n",
    "\n",
    "### Naïve Bayes\n",
    "\n",
    "Dans cette sous section nous allons introduire un autre algorithme\n",
    "souvent utilisé dans le cadre des problèmes de classification. Cet\n",
    "algorithme est connu sous le nom de **Naïve Bayes**, naïve parce qu'il\n",
    "fait une simple hypothèse sur les données, celle qui suppose qu'elles\n",
    "sont indépendantes les une des autres, même si ceci n'est souvent pas\n",
    "vrai en pratique.\n",
    "\n",
    "Les systèmes modernes populaires comme la classification des émails\n",
    "reçus comme **spam** ou **non-spam** sont souvent implémentés avec\n",
    "naïves Bayes et quelques fois leur performance est difficile à surpasser\n",
    "par des algorithmes sophistiqués.\n",
    "\n",
    "Naïve Bayes fait partie des algorithmes de type **génératif**, qui sont\n",
    "différents des algorithmes vus jusque-là qui sont de type\n",
    "**discriminatif**.\n",
    "\n",
    "L'une des grandes différences entre les algorithmes de type génératif et\n",
    "ceux dits discriminatifs réside dans le fait que les premiers font une\n",
    "hypothèse sur les données $\\mathbb{P}(\\mathbf{x}|y)$ tandis que les\n",
    "derniers font une hypothèse sur les étiquettes (classes)\n",
    "$\\mathbb{P}(y|\\mathbf{x})$.\n",
    "\n",
    "Pour ceux qui sont familiers avec les notions mathématiques, peut être\n",
    "que vous vous êtes posé la question si cet algorithme a un lien avec la\n",
    "règle de Bayes (Naïve Bayes) ? OUI! vous avez raison car cette formule\n",
    "nous donne un lien entre les algorithmes de type discriminatif et ceux\n",
    "de type génératif.\n",
    "\n",
    "Rappelons la formule [\\[naivebayes\\]](#naivebayes){reference-type=\"ref\"\n",
    "reference=\"naivebayes\"}\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\mathbb{P}(\\mathbf{x}|y) &= \\frac{\\mathbb{P}(y|\\mathbf{x}) \\mathbb{P}(\\mathbf{x})}{\\mathbb{P}(y)}.\\end{aligned}$$\n",
    "\n",
    "Considérons le cas de la classification des emails (spam ou no-spam).\n",
    "Nous pouvons ré-écrire la formule précédente comme : $$\\begin{aligned}\n",
    "    \\mathbb{P}(\\mbox{document} |\\mbox{classe}) &= \\frac{\\mathbb{P}(\\mbox{classe}|\\mbox{document}) \\mathbb{P}(\\mbox{document})}{\\mathbb{P}(\\mbox{classe})}. \\end{aligned}$$\n",
    "Avec **document** qui représente l'ensemble des émails, et **classe**\n",
    "leur catégorie.\n",
    "\n",
    "Pour mieux illustrer la notion introduite dans le paragraphe précédent,\n",
    "réfléchissons sur un exemple pratique. Disons que vous êtes responsable\n",
    "d'un champ de feuille de manioc et vous voulez avoir un système qui vous\n",
    "alarme dès qu'une chèvre entre dans le champ. Nous supposerons (non\n",
    "réaliste) que dans cette contrée nous ne pouvons avoir que deux espèces\n",
    "d'animaux, chèvre et chien, donc nous avons deux catégories\n",
    "$c_1$=\\\"chèvre\\\" et $c_2$ = \\\"chien\\\".\n",
    "\n",
    "Comme vous l'avez sûrement appris dans ce cours, les algorithmes que\n",
    "nous utilisons en apprentissage automatique ne prennent en entrée que\n",
    "les données de type numérique. Alors nos données deviennent :\n",
    "\n",
    "1.  $\\mathbf{x}$ qui représente certaines caractéristiques des deux\n",
    "    animaux, par exemple : 'couleur', 'cris', 'vitesse', ..., toutes ces\n",
    "    caractéristiques ont une représentation numérique (cris : bêler=0,\n",
    "    aboyer=1, \\...).\n",
    "\n",
    "2.  $y$ qui prend la valeur \\\"0\\\" pour une chèvre et \\\"1\\\" pour un\n",
    "    chien.\n",
    "\n",
    "Dans ce contexte, un algorithme de type discriminatif va chercher à\n",
    "apprendre une application (mapping) de l'espace des $\\mathbf{x}$ dans\n",
    "l'espace des étiquettes $\\{0, 1\\}$; en d'autres termes, ce type\n",
    "d'algorithmes va chercher à trouver une ligne (ou hyperplan) qui va\n",
    "séparer les chiens des chèvres étant données les caractéristiques\n",
    "($\\mathbf{x}$) observées, tandis que celui de type génératif va se\n",
    "focaliser à la modélisation des caractéristiques qui distinguent un\n",
    "chien d'une chèvre.\n",
    "\n",
    "::: {.algorithm}\n",
    "::: {.algorithmic}\n",
    "**fonction** $Entrainer\\_Naïve\\_Bayes(D,\\ C)$:        **Pour chaque**\n",
    "classe dans $C$:        $N_{doc}=$ nombre de documents dans $D$       \n",
    "$N_{c}=$ nombre de documents de classe $c$ dans $D$       \n",
    "$\\log \\operatorname{Prob}[c]= \\log\\frac{N_c}{N_{doc}}$        $V=$\n",
    "vocabulaire de $D$        $\\operatorname{classedoc}[c]=$\n",
    "**ajouter**($d$) pour tout $d\\in D$ avec pour classe $c$        **Pour\n",
    "chaque** mot $w$ de classe $c \\in C$ dans $V$:            \n",
    "**compter**(w, c) = nombre d'occurrence du mot $w$ dans\n",
    "$\\operatorname{classedoc}[c]$            \n",
    "$\\log \\operatorname{Prob\\_wc} [w, c] \\leftarrow \\log \\frac{\\operatorname{compter}(w, c)}{\\sum_{w^{\\prime} \\in V} \\left(\\text {compter}\\left(w^{\\prime}, c\\right)\\right)}$\n",
    "**retourner** $\\log \\operatorname{Prob}$,\n",
    "$\\log \\operatorname{Prob\\_wc},\\ V$\n",
    ":::\n",
    "\n",
    "[\\[train_naive\\]]{#train_naive label=\"train_naive\"}\n",
    ":::\n",
    "\n",
    "::: {.algorithm}\n",
    "::: {.algorithmic}\n",
    "**fonction**\n",
    "$Tester\\_naive\\_bayes(testdoc,\\ logProb,\\ logProb\\_wc,\\ C,\\ V)$:\n",
    "      **Pour chaque** classe $c \\in C$:\n",
    "         $\\operatorname{somme[c]} = \\log \\operatorname{Prob}[c]$\n",
    "      **Pour chaque** position i dans $testdoc$:\n",
    "         $\\operatorname{mot} = \\operatorname{testdoc[i]}$\n",
    "              $\\textbf{Si} \\operatorname{mot} \\in V:$\n",
    "                 $\\operatorname{somme[c]}=\\operatorname{somme[c]}+\\log$\n",
    "$\\operatorname{Prob\\_wc}[mot, c]$\n",
    "\n",
    "       **retourner**\n",
    "$\\underset{c}{\\arg\\max} \\quad  \\operatorname{somme[c]}$\n",
    ":::\n",
    "\n",
    "[\\[test_naive\\]]{#test_naive label=\"test_naive\"}\n",
    ":::\n",
    "\n",
    "Ainsi, parlons de comment nous pouvons construire un modèle de\n",
    "classification en utilisant Naïve Bayes.\n",
    "\n",
    "#### Entraînement du Naïve Bayes (Exemple Pratique)\n",
    "\n",
    "Considérons le cas de l'analyse de sentiments, sur base des commentaires\n",
    "de gens après avoir suivi un film. Pour raison de simplicité nous\n",
    "considérerons un exemple de quelques phrases et leurs classes\n",
    "correspondantes.\n",
    "\n",
    "$$\\begin{array}{lll}\n",
    "    \\hline \\text{Mode} & \\text { Classe } & \\multicolumn{1}{c} {\\text { Documents }} \\\\\n",
    "    \\hline \\text{ Train } & - & \\text { tout simplement ennuyeux } \\\\\n",
    "    & - & \\text { tout à fait prévisible et manque d'énergie } \\\\\n",
    "    & - & \\text { pas de surprises et très peu de rires } \\\\\n",
    "    & + & \\text { très intéressant } \\\\\n",
    "    & + & \\text { le film le plus amusant de l'année } \\\\\n",
    "    \\hline \\text { Test } & ? & \\text { prévisible sans amusement }\n",
    "    \\end{array}$$ [\\[fig:my_label\\]]{#fig:my_label label=\"fig:my_label\"}\n",
    "\n",
    "Nous commencerons par calculer le **à priori** pour les deux classes\n",
    "comme élaboré dans l'algorithme\n",
    "[\\[train_naive\\]](#train_naive){reference-type=\"ref\"\n",
    "reference=\"train_naive\"}.\n",
    "\n",
    "$$\\mathbb{P}(+) = \\log \\frac{N_{+}}{N_{doc}}= \\log \\frac{2}{5}= -0.916290731874155$$\n",
    "\n",
    "$$\\mathbb{P}(-) = \\log \\frac{N_{-}}{N_{doc}} = \\log \\frac{3}{5} = -0.5108256237659907$$\n",
    "\n",
    "Comme vous l'avez remarqué, les formules que nous utilisons pour notre\n",
    "algorithme sont dans l'échelle logarithmique, ceci, pour raison d'éviter\n",
    "ce qui est connu en anglais comme underflow (quand les valeurs sont très\n",
    "proches de zéro au point d'être vue par l'ordinateur comme zéro),\n",
    "overflow (quand les valeurs sont très grandes) mais aussi pour augmenter\n",
    "la vitesse de calcul.\n",
    "\n",
    "La prochaine étape consiste à définir notre vocabulaire $V$. Le $V$ est\n",
    "un ensemble qui contient les mots uniques de nos données.\n",
    "\n",
    "V = {'tout', 'simplement', 'ennuyeux', 'à', 'fait', 'prévisible', 'et',\n",
    "'manque', 'd', 'énergie', 'pas', 'de', 'surprises', 'très', 'peu',\n",
    "'rires', 'intéressant', 'le', 'film', 'plus', 'amusant', 'l', 'année'}.\n",
    "\n",
    "Nous avons au total $23$ mots uniques. Nous allons par la suite,\n",
    "calculer les valeurs de $classedoc$ pour les deux classes:\n",
    "\n",
    "-   $\\operatorname{classedoc}[+]$ = \\[\\\"très intéressant\\\", \\\"le film le\n",
    "    plus amusant de l'année\\\"\\]\n",
    "\n",
    "-   $\\operatorname{classedoc}[-]$ = \\[\\\"tout simplement ennuyeux\\\",\n",
    "    \\\"tout à fait prévisible et manque d'énergie\\\", \\\"pas de surprises\n",
    "    et très peu de rires\\\"\\].\n",
    "\n",
    "Calculons ensuite le logarithme de la probabilité (d'apparition) de\n",
    "chaque mot dans notre vocabulaire étant donné une classe particulière.\n",
    "En pratique, pour le calcul de $\\log \\operatorname{Prob\\_wc}$, il arrive\n",
    "que nous rencontrons de nouveaux mots qui n'étaient pas présents dans\n",
    "l'étape d'entraînement, ceci conduit au fait que\n",
    "$\\log \\operatorname{Prob\\_wc} =  \\log(0)$ qui n'est pas défini. Alors\n",
    "pour contourner ce problème, plusieurs alternatives existent dans la\n",
    "littérature; dans le contexte de notre exemple, nous allons utiliser la\n",
    "technique appelée \\\"add-one (Laplace) smothing\\\" qui va transformer la\n",
    "formule de $\\log \\operatorname{Prob}\\_wc$ fournie dans l'algorithme\n",
    "[\\[train_naive\\]](#train_naive){reference-type=\"ref\"\n",
    "reference=\"train_naive\"}: $$\\begin{aligned}\n",
    "\\displaystyle \\log \\operatorname{Prob}\\_wc &= \\log \\frac{\\operatorname{compter}(w, c)+1}{\\sum_{w^{\\prime} \\in V} \\left(\\text {compter}\\left(w^{\\prime}, c\\right)+1\\right)}\\\\\n",
    "&=\\log \\frac{\\operatorname{compter}(w, c)+1}{\\sum_{w^{\\prime} \\in V} \\left(\\operatorname {compter}\\left(w^{\\prime}, c\\right)\\right)+|V|}\\end{aligned}$$\n",
    "En réalité comme vous l'avez peut être remarqué, l'algorithme de Naïve\n",
    "Bayes est simplement un comptage systématique des mots.\n",
    "\n",
    "Notre tâche ici est de classifier la phrase \\\"*prévisible sans\n",
    "amusement*\\\" comme soit positive (+) ou négative (-).\n",
    "\n",
    "::: {.center}\n",
    "                             Sentiment positive (+)                                                         Sentiment négative (-)\n",
    "  ----------------------------------------------------------------------------- -------------------------------------------------------------------------------\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}