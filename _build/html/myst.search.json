{"version":"1","records":[{"hierarchy":{"lvl1":"Introduction Générale à l’Apprentissage Automatique"},"type":"lvl1","url":"/chapter1","position":0},{"hierarchy":{"lvl1":"Introduction Générale à l’Apprentissage Automatique"},"content":"Contenu à venir\n\nCette section sera complétée bientôt.","type":"content","url":"/chapter1","position":1},{"hierarchy":{"lvl1":"Introduction Générale à l’Apprentissage Automatique","lvl2":"C’est quoi Apprentissage Automatique"},"type":"lvl2","url":"/chapter1#cest-quoi-apprentissage-automatique","position":2},{"hierarchy":{"lvl1":"Introduction Générale à l’Apprentissage Automatique","lvl2":"C’est quoi Apprentissage Automatique"},"content":"Contenu à venir\n\nCette section sera complétée bientôt.","type":"content","url":"/chapter1#cest-quoi-apprentissage-automatique","position":3},{"hierarchy":{"lvl1":"Introduction Générale à l’Apprentissage Automatique","lvl2":"Convention Mathématiques pour le document"},"type":"lvl2","url":"/chapter1#convention-math-matiques-pour-le-document","position":4},{"hierarchy":{"lvl1":"Introduction Générale à l’Apprentissage Automatique","lvl2":"Convention Mathématiques pour le document"},"content":"Les matrices seront notées en lettre majuscule et seront mises en gras. Par exemple \\mathbf{X}\n\nLes vecteurs seront notés en lettre miniscule et mises en gras. Par exemple, \\mathbf{x}.\n\nLécriture mathématique de probabilités, espérance seront respectivement: \\mathbb{P}, \\mathbb{E}\n\nIl sera aussi important de ponctuer les équations.\n\nNuméroter les équations principales.\n\nTous les ensemble seront notés en utilisant \\mathbb{R} par example.\n\nles expressions mathématiques qui sont écrites à travers les textes seront écrites dans \\operatorname{Prob}\n\nSi c’est un symbole qui est un vecteur, on écrit (par exemple, si c’est alpha) \\boldsymbol{\\alpha} par exemple [\n\n2020 Anaconda (2020)] .\n\n2020 Anaconda, Inc., ed. Accessed July 2020. Anaconda Documentation. Anaconda, \n\nhttp://​docs​.anaconda​.com​/anaconda​/navigator/.","type":"content","url":"/chapter1#convention-math-matiques-pour-le-document","position":5},{"hierarchy":{"lvl1":"Pré-requis"},"type":"lvl1","url":"/chapter2","position":0},{"hierarchy":{"lvl1":"Pré-requis"},"content":"Python est le langage de programmation préféré des data scientists. Ils ont besoin d’un langage facile à utiliser, avec une disponibilité décente des bibliothèques et une grande communauté. Les projets ayant des communautés inactives sont généralement moins susceptibles de mettre à jour leurs plateformes. Mais alors, pourquoi Python est-il populaire en data science ?\n\nPython est connu depuis longtemps comme un langage de programmation simple à maîtriser, du point de vue de la syntaxe. Python possède également une communauté active et un vaste choix de bibliothèques et de ressources. En conséquence, vous disposez d’une plateforme de programmation qu’il est logique d’utiliser avec les technologies émergentes telles que l’apprentissage automatique (Machine Learning) et la data science.","type":"content","url":"/chapter2","position":1},{"hierarchy":{"lvl1":"Pré-requis","lvl2":"Langage Python et ses Librairies"},"type":"lvl2","url":"/chapter2#langage-python-et-ses-librairies","position":2},{"hierarchy":{"lvl1":"Pré-requis","lvl2":"Langage Python et ses Librairies"},"content":"Python est un langage de programmation puissant et facile à apprendre. Il dispose de structures de données de haut niveau et permet une approche simple mais efficace de la programmation orientée objet. Parce que sa syntaxe est élégante, que son typage est dynamique et qu’il est interprété, Python est un langage idéal pour l’écriture de scripts quand on fait de l’apprentissage automatique et le développement rapide d’applications dans de nombreux domaines et sur la plupart des plateformes.","type":"content","url":"/chapter2#langage-python-et-ses-librairies","position":3},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Installation de Python et Anaconda","lvl2":"Langage Python et ses Librairies"},"type":"lvl3","url":"/chapter2#installation-de-python-et-anaconda","position":4},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Installation de Python et Anaconda","lvl2":"Langage Python et ses Librairies"},"content":"L’installation de Python peut être un vrai challenge. Déjà il faut se décider entre les versions 2.X et 3.X du langage, par la suite, choisir les librairies nécessaires (ainsi que les versions compatibles) pour faire de l’apprentissage automatique (Machine Learning) ; sans oublier les subtilités liées aux différents systèmes d’exploitation (Windows, Linux, Mac...) qui peuvent rendre l’installation encore plus douloureuse.\n\nDans cette partie nous allons installer pas à pas un environnement de développement Python en utilisant Anaconda. A l’issue de cette partie, nous aurons un environnement de développement fonctionnel avec les librairies (packages) nécessaires pour faire de l’apprentissage automatique (Machine Learning).\n\nQu’est-ce qu’Anaconda ?\n\nL’installation d’un environnement Python complet peut être assez complexe. Déjà, il faut télécharger Python et l’installer, puis télécharger une à une les librairies (packages) dont on a besoin. Parfois, le nombre de ces librairies peut être grand. Par ailleurs, il faut s’assurer de la compatibilité entre les versions des différents packages qu’on a à télécharger. Bref, ce n’est pas amusant!\n\nAlors Anaconda est une distribution Python. À son installation, Anaconda installera Python ainsi qu’une multitude de packages dont vous pouvez consulter la \n\nliste. Cela nous évite de nous ruer dans les problèmes d’incompatibilités entre les différents packages. Finalement, Anaconda propose un outil de gestion de packages appelé Conda. Ce dernier permettra de mettre à jour et installer facilement les librairies dont on aura besoin pour nos développements.\n\nTéléchargement et Installation de Anaconda\n\nNote: Les instructions qui suivent ont été testées sur Linux/Debian. Le même processus d’installation pourra s’appliquer pour les autres systèmes d’exploitation.\n\nPour installer Anaconda sur votre ordinateur, vous allez vous rendre sur le \n\nsite officiel  depuis lequel l’on va télécharger directement la dernière version d’Anaconda. Prenez la version du binaire qu’il vous faut :\n\nChoisissez le système d’exploitation cible (Linux, Windows, Mac, etc...)\n\nSélectionnez la version 3.X (à l’heure de l’écriture de ce document, c’est la version 3.8 qui est proposée, surtout pensez à toujours installer la version la plus récente de Python), compatible (64 bits ou 32 bits) avec l’architecture de votre ordinateur.\n\nAprès le téléchargement, si vous êtes sur Windows, alors rien de bien compliqué : double-cliquez sur le fichier exécutable et suivez les instructions classiques d’installation d’un logiciel sur Windows.\n\nSi par contre vous êtes sur Linux, alors suivez les instructions qui suivent:\n\nOuvrez votre terminal et assurez-vous que votre répertoire de travail est celui dans lequel se trouve votre fichier d’installation.\n\nExécutez la commande suivante (rassurez-vous du nom du fichier d’installation, il peut changer selon la version que vous choisissez) :bash Anaconda3-2020.02-Linux-x86_64.sh\n\nAprès que l’installation se soit déroulée normalement, éditez le fichier caché .bashrc pour ajouter le chemin d’accès à Anaconda. Pour cela exécutez les commandes suivantes :cd ~\ngedit .bashrc\n\nAjoutez cette ligne à la dernière ligne du fichier que vous venez d’ouvrir :export PATH=~/anaconda3/bin:$PATH\n\nMaintenant que c’est fait, enregistrez le fichier et fermez-le. Puis exécutez les commandes suivantes :conda init\npython\n\nPour ce qui est de l’installation sur Mac, veuillez suivre la procédure d’installation dans la \n\ndocumentation d’Anaconda.\n\nIl existe une distribution appelée \n\nMiniconda qui est un programme d’installation minimal gratuit pour conda. Il s’agit d’une petite version bootstrap d’Anaconda qui inclut uniquement conda, Python, les packages dont ils dépendent, et un petit nombre d’autres packages utiles.\n\nTerminons cette partie en nous familiarisant avec quelques notions de la programmation Python.\n\nPremière utilisation de Anaconda\n\nLa distribution Anaconda propose deux moyens d’accéder à ses fonctions : soit de manière graphique avec Anaconda-Navigator, soit en ligne de commande (depuis Anaconda Prompt sur Windows, ou un terminal pour Linux ou MacOS). Sous Windows ou MacOs, démarrez Anaconda-Navigator dans le menu des programmes. Sous Linux, dans un terminal, tapez la commande suivante (cette commande est aussi disponible dans le prompt de Windows) :anaconda-navigator\n\nAnaconda-Navigator propose différents services (déjà installés, ou à installer). Son onglet Home permet de lancer le service désiré. Les principaux services à utiliser pour développer des programmes Python sont :\n\nSpyder : un environnement de développement intégré (IDE) pour Python\n\nIDE Python : un autre environnement de développement\n\nJupyter Notebook et Jupyter Lab : permettent de combiner des cellules de commandes Python (code) et des cellules de texte (Markdown)\n\nPour la prise en main de Python nous allons utiliser jupyter lab.","type":"content","url":"/chapter2#installation-de-python-et-anaconda","position":5},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Prise en main de Python","lvl2":"Langage Python et ses Librairies"},"type":"lvl3","url":"/chapter2#prise-en-main-de-python","position":6},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Prise en main de Python","lvl2":"Langage Python et ses Librairies"},"content":"Nous avons préparé un notebook qui nous permettra d’aller de zéro à demi-héros en Python. Le notebook se trouve \n\nici.","type":"content","url":"/chapter2#prise-en-main-de-python","position":7},{"hierarchy":{"lvl1":"Pré-requis","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl2","url":"/chapter2#les-bases-math-matiques-pour-lapprentissage-automatique","position":8},{"hierarchy":{"lvl1":"Pré-requis","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Dans cette section, nous allons présenter les notions mathématiques essentielles à l’apprentissage automatique (machine learning). Nous n’aborderons pas les théories complexes des mathématiques afin de permettre aux débutants (en mathématiques) ou mêmes les personnes hors du domaine mais intéressées à l’apprentissage automatique de pouvoir en profiter.","type":"content","url":"/chapter2#les-bases-math-matiques-pour-lapprentissage-automatique","position":9},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Algèbre linéaire et Analyse","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl3","url":"/chapter2#alg-bre-lin-aire-et-analyse","position":10},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Algèbre linéaire et Analyse","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Définition d’espaces vectoriels. Un espace vectoriel est un triplet (V, +, *) formé d’un ensemble V muni de deux lois,\\begin{aligned}\n +:\\quad & V\\times V \\longrightarrow{V}\\\\\n&(u,v)\\mapsto u+v \\\\\n\\text{et} \\qquad \\qquad\\\\\n*:\\quad &\\mathbb{K}\\times V \\longrightarrow{V}, \\text{ avec $\\mathbb{K}$ un corps commutatif}\\\\\n&(\\lambda,v)\\mapsto \\lambda * v=\\lambda v\n\\end{aligned}\n\nqui vérifient:\\begin{aligned}\n&\\bullet \\text{ associativité de } + :\\\\\n&   \\forall u,v, w \\in V, \\quad (u+v)+w=u+(v+w)\\\\\n&\\bullet \\text{ commutativité de } + :\\\\\n&    \\forall u,v\\in V,\\quad u+v=v+u\\\\\n&\\bullet \\text{ existence d'élément neutre pour } + :\\\\\n&    \\exists~ e \\in V : \\forall u \\in V, \\quad u+e=e+u=u\\\\\n&\\bullet \\text{ existence d'élément opposé pour } + :\\\\ &\\forall u \\in V, \\exists ~ v \\in V  :u+v=v+u=0. \\text{ On note } v=-u \\text{ et } v \\text{ est appelé l'opposé de } u\\\\\n&\\bullet \\text{ existence de l'unité pour } * :\\\\\n&    \\exists~ e \\in \\mathbb{K} \\text{ tel que } \\forall u\\in V,\\quad e*u=u\\\\\n&\\bullet\\text{ associativité de * } :\\\\\n&    \\forall (\\lambda_1, \\lambda_2, u) \\in \\mathbb{K} \\times \\mathbb{K}\\times V,\\quad\n    (\\lambda_1 \\lambda_2)* u =\\lambda_1*(\\lambda_2 * u)\\\\\n&\\bullet \\text{ somme de vecteurs (distributivité de $*$ sur $+$) } :\\\\\n&    \\forall (\\lambda, u, v) \\in \\mathbb{K}\\times V\\times V, \\quad\\lambda*(u+v)=\\lambda * u+\\lambda * v\\\\\n&\\bullet\\text{ somme de scalaires } :\\\\\n&    \\forall (\\lambda_1, \\lambda_2, u) \\in \\mathbb{K} \\times \\mathbb{K}\\times V,\\quad\n    (\\lambda_1+\\lambda_2) * u=\\lambda_1 * u +\\lambda_2 * u.\n\\end{aligned}\n\nRemarque 1: Les éléments de V sont appelés des vecteurs, ceux de \\mathbb{K} sont appelés des scalaires et l’élément neutre pour + est appelé vecteur nul. Finalement, V est appelé \\mathbb{K}-espace vectoriel ou espace vectoriel sur \\mathbb{K}.\n\nBase d’un espace vectoriel. Soit V un \\mathbb{K}-espace vectoriel. Une famille de vecteurs \\mathcal{B}=\\big\\{b_1, b_2, \\dots, b_n\\big\\} est appelée base de V si les deux propriétés suivantes sont satisfaites:\n\n\\forall u \\in V, \\exists~ c_1, \\dots, c_n \\in \\mathbb{K} tels que \\displaystyle u = \\sum_{i=1}^{n}c_i b_i (On dit que \\mathcal{B} est \\textbf{une famille génératrice} de V).\n\n\\displaystyle \\forall \\lambda_1, \\dots, \\lambda_n \\in \\mathbb{K}, \\quad\\sum_{i=1}^{n}\\lambda_i b_i=0\\Longrightarrow \\lambda_i = 0 \\quad\\forall i. (On dit que les éléments de \\mathcal{B} sont linéairement indépendants).\n\nLorsque \\displaystyle u = \\sum_{i=1}^{n}c_i b_i, on dit que c_1, \\dots, c_n sont les coordonnées de u dans la base \\mathcal{B}. Si de plus aucune confusion n’est à craindre, on peut écrire:\\begin{aligned} \n    \\mathbf{u}=\\begin{bmatrix}\nc_1\\\\c_2\\\\ \\vdots\\\\ c_n\n\\end{bmatrix}    \n\\end{aligned}\n\nDéfinition. Le nombre d’éléments dans une base d’un espace vectoriel est appelé dimension de l’espace vectoriel.\n\nNB: Un espace vectoriel ne peut être vide (il contient toujours le vecteur nul). L’espace vectoriel nul \\{0\\} n’a pas de base et est de dimension nulle. Tout espace vectoriel non nul de dimension finie admet une infinité de bases mais sa dimension est unique.\n\nExemples d’espaces vectoriels: Pour tous n,m\\ge1, l’ensemble des matrices \\mathcal{M}_{nm} à coefficients réels et l’ensemble \\mathbb{R}^n sont des \\mathbb{R}-espace vectoriels. En effet, il est très facile de vérifier que nos exemples satisfont les huit propriétés énoncées plus haut. Dans le cas particulier V=\\mathbb{R}^n, toute famille d’exactement n vecteurs linéairement indépendants en est une base. En revanche, toute famille de moins de n vecteurs ou qui contient plus que n vecteurs ne peut être une base de \\mathbb{R}^n.\n\nMatrices: Soit \\mathbb{K} un corps commutatif. Une matrice en mathématiques à valeurs dans \\mathbb{K} est un tableau de nombres, où chaque nombre est un élément de \\mathbb{K}. Chaque ligne d’une telle matrice est un vecteur (élément d’un \\mathbb{K}-espace vectoriel). Une matrice est de la forme: \\mathbf{M}=\\begin{bmatrix}\na_{11} &a_{12} \\dots a_{1n}\\\\\na_{21} &a_{22} \\dots a_{2n}\\\\\n\\vdots\\\\\na_{m1}& a_{m2} \\dots a_{mn}\n\\end{bmatrix}\n\nOn note aussi \\mathbf{M}={(a_{ij}})_{1\\le i\\le m, 1\\le j\\le n}.\n\nLa matrice ci-dessus est carrée si m=n. Dans ce cas, la suite [a_{11}, a_{22}, \\dots, a_{mm}] est appelée diagonale de M. Si tous les coefficients hors de la diagonale sont zéro, on dit que la matrice est diagonale. Une matrice avec tous ses coefficients nuls est dite matrice nulle.\n\nProduit de matrices. Soient \\mathbf{A}={(a_{ij}})_{1\\le i\\le m, 1\\le j\\le n}, \\mathbf{B}={(b_{ij}})_{1\\le i\\le n, 1\\le j\\le q} deux matrices. On définit le produit de \\mathbf{A} par \\mathbf{B} et on note \\mathbf{A}\\times \\mathbf{B} ou simplement \\mathbf{A}\\mathbf{B}, la matrice M définie par:\\begin{aligned}\n    \\mathbf{M}_{ij} = \\sum_{\\ell=1}^{n}a_{i\\ell}b_{\\ell j}, \\text{ pour tout } i \\text{ et } j.\n\\end{aligned}\n\nImportant.\n\nLe produit \\mathbf{AB} est possible si et seulement si le nombre de colonnes de \\mathbf{A} est égal au nombre de lignes de \\mathbf{B}.\n\nDans ce cas, \\mathbf{AB} a le même nombre de lignes que \\mathbf{A} et le même nombre de colonnes que \\mathbf{B}.\n\nUn autre point important à noter est que le produit matriciel n’est pas commutatif (\\mathbf{AB} n’est pas toujours égal à \\mathbf{BA}).\n\nExemple. Soient les matrices \\mathbf{A} et \\mathbf{B} définies par: \\mathbf{A} = \\begin{bmatrix}\n2 & -3 & 0\\\\\n5 &11 & 5\\\\\n1& 2 & 3\n\\end{bmatrix} \\qquad \\mathbf{B} = \\begin{bmatrix}\n1 & 3\\\\\n-5 &1\\\\\n1 & 2\n\\end{bmatrix}\n\nLe nombre de colonnes de la matrice \\mathbf{A} est égal au nombre de lignes de la matrice \\mathbf{B}.\n\n\\mathbf{AB} = \\begin{bmatrix}\n2\\times 1 + (-3)\\times(-5) + 0\\times 1 & 2\\times3+(-3)\\times1+0\\times2\\\\\n5\\times1+11\\times(-5)+5\\times1 &5\\times3+11\\times1+5\\times2\\\\\n1\\times1+2\\times(-5)+3\\times1& 1\\times3+2\\times1+3\\times2\n\\end{bmatrix} = \\begin{bmatrix}\n17 & 3\\\\\n-45 & 33\\\\\n-6 & 11\n\\end{bmatrix}\n\nLe produit \\mathbf{BA} n’est cependant pas possible.\n\nSomme de matrices et multiplication d’une matrice par un scalaire. La somme de matrices et multiplication d’une matrice par un scalaire se font coefficients par coefficients.\n\nAvec les matrice \\mathbf{A}, \\mathbf{B} de l’exemple précédent, et \\mathbf{C}=\\begin{bmatrix}\n-2 & -7 & 3\\\\\n5 &10 & 5\\\\\n12& 9 & 3\n\\end{bmatrix}, on a:\\mathbf{A}+ \\mathbf{C} = \\begin{bmatrix}\n2+(-2) & -3+(-7) & 0+3\\\\\n5+5 &11+10 & 5+5\\\\\n1+12& 2+9 & 3+3\n\\end{bmatrix}=\\begin{bmatrix}\n0 & -10 & 3\\\\\n10 &21 & 10\\\\\n13& 11 & 6\n\\end{bmatrix} \\text{ et pour tout } \\lambda \\in \\mathbb{R}, \\quad\n\\lambda \\mathbf{B} = \\begin{bmatrix}\n\\lambda & 3 \\lambda\\\\\n-5 \\lambda & \\lambda\\\\\n\\lambda & 2\\lambda\n\\end{bmatrix}\n\nNB: La somme de matrice n’est définie que pour des matrices de même taille.\n\nDéterminant d’une matrice. Soit \\mathbf{A}=(a_{ij})_{1\\le i\\le n, 1\\le j\\le n} une matrice carrée d’ordre n. Soit \\mathbf{A}_{i,j} la sous-matrice de \\mathbf{A} obtenue en supprimant la ligne i et la colonne j de \\mathbf{A}. On appelle déterminant (au développement suivant la ligne i) de \\mathbf{A} et on note \\operatorname{det}(\\mathbf{A}), le nombre\\begin{aligned}\n    \\operatorname{det}(\\mathbf{A}) = \\sum_{j=1}^{n}a_{ij}(-1)^{i+j}\\operatorname{det}(\\mathbf{A}_{i,j}),\n\\end{aligned}\n\navec le déterminant d’une matrice carrée de taille 2\\times 2 donné par:\\begin{aligned}\n    \\operatorname{det} \\left(\\begin{bmatrix}\na & b\\\\\nc & d\\\\\n\\end{bmatrix}\\right) = ad-bc.\n\\end{aligned}\n\nNB: Le développement suivant toutes les lignes donne le même résultat. Le déterminant d’une matrice a une deuxième formulation dite de \n\nLeibniz que nous n’introduisons pas dans ce document.\n\nInverse d’une matrice. Soit \\mathbf{A} une matrice carrée d’ordre n. \\mathbf{A} est inversible s’il existe une autre matrice notée \\mathbf{A}^{-1} telle que \\mathbf{A}\\mathbf{A}^{-1}=\\mathbf{A}^{-1}\\mathbf{A}=\\mathbf{I}_n, où \\mathbf{I}_n est la matrice identité de taille n\\times n. Les matrices, leurs inverses et les opérations sur les matrices sont d’une importance capitale dans l’apprentissage automatique.\n\nVecteurs propres, valeurs propres d’une matrice. Soient E un espace vectoriel et \\mathbf{A} une matrice. Un vecteur \\mathbf{v}\\in E est dit vecteur propre de \\mathbf{A} si \\mathbf{v}\\neq 0 et il existe un scalaire \\lambda tel que \\mathbf{A}\\mathbf{v}=\\lambda \\mathbf{v}. Dans ce cas, on dit que \\lambda est la valeur propre associée au vecteur propre \\mathbf{v}.\n\nApplications linéaires et changement de base d’espaces vectoriels. Soient (E, \\mathcal{B}),\\ (F, \\mathcal{G}) deux \\mathbb{K}-espace vectoriels, chacun muni d’une base et f:\\ E \\rightarrow F une application. On dit que f est linéaire si les propriétés suivantes sont satisfaites:\n\nPour tous \\mathbf{u}, \\mathbf{v}\\in E, f(\\mathbf{u}+\\mathbf{v})=f(\\mathbf{u})+f(\\mathbf{v}).\n\nPour tout (\\lambda, \\mathbf{u}) \\in \\mathbb{K}\\times E, f(\\lambda \\mathbf{u})=\\lambda f(\\mathbf{u}).\n\nOn suppose que \\mathcal{B}=\\{e_1, e_2, \\dots, e_n\\} et \\mathcal{G}=\\{e'_1, e'_2, \\dots, e'_m\\}. De manière équivalente, f est linéaire s’il existe une matrice \\mathbf{A} telle que pour tout \\mathbf{x}\\in E, \\quad f(x)=\\mathbf{A}\\mathbf{x}. Dans ce cas, la matrice \\mathbf{A} que l’on note Mat_{\\mathcal{B},\\mathcal{G}}(f) est appelée matrice (représentative) de l’application linéaire f dans le couple de coordonnées (\\mathcal{B},\\mathcal{G}). La matrice \\mathbf{A} est unique et de taille m\\times n (notez la permutation dimension de l’espace d’arrivée puis dimension de l’espace de départ dans la taille de la matrice). De plus, la colonne j de la matrice \\mathbf{A} est constituée des coordonnées de f(e_j) dans la base \\mathcal{G} de F. Lorsque E=F, l’application linéaire f est appelée endomorphisme de E et on écrit simplement Mat_{\\mathcal{B}}(f) au lieu de Mat_{\\mathcal{B},\\mathcal{G}}(f).\n\nDéfinition. Soient E un espace vectoriel de dimension finie et, \\mathcal{B} et \\mathcal{C}, deux bases de E. On appelle matrice de passage de la base \\mathcal{B} à la base \\mathcal{C} la matrice de l’application identité\\begin{aligned} \n    &id_E: (E, \\mathcal{C})\\rightarrow (E, \\mathcal{B})\\\\\n     &x \\mapsto x\n\\end{aligned}\n\nCette matrice est notée P_{\\mathcal{B}}^{\\mathcal{C}} et on a P_{\\mathcal{B}}^{\\mathcal{C}}:=Mat_{\\mathcal{C},\\mathcal{B}}(id_E). Note: Si \\mathbf{x}=\\begin{bmatrix}\nx_1\\\\x_2\\\\ \\vdots\\\\ x_n\n\\end{bmatrix} est un vecteur de E exprimé dans la base \\mathcal{B}, alors l’expression de \\mathbf{x} dans la base \\mathcal{C} est donnée par \\begin{bmatrix}\nx'_1\\\\x'_2\\\\ \\vdots\\\\ x'_n\n\\end{bmatrix}=(P_{\\mathcal{B}}^{\\mathcal{C}})^{-1}\\mathbf{x}=P_{\\mathcal{C}}^{\\mathcal{B}}\\mathbf{x}.\n\nExemple. Si E=\\mathbb{R}^3 avec ses deux bases\\mathcal{B}=\\left(\n\\begin{bmatrix}\n1\\\\0\\\\0\n\\end{bmatrix},\\begin{bmatrix}\n0\\\\1\\\\0\n\\end{bmatrix},\\begin{bmatrix}\n0\\\\0\\\\1\n\\end{bmatrix}\n\\right) \\text{ et } \\mathcal{C}=\\left(\n\\begin{bmatrix}\n-1\\\\2\\\\3\n\\end{bmatrix},\\begin{bmatrix}\n0\\\\1\\\\5\n\\end{bmatrix},\\begin{bmatrix}\n0\\\\0\\\\1\n\\end{bmatrix}\n\\right),\n\non a P_{\\mathcal{B}}^{\\mathcal{C}} = \\begin{bmatrix}\n-1&0&0\\\\\n2&1&0\\\\\n3&5&1\n\\end{bmatrix} (c’est-à-dire qu’on exprime les vecteurs de \\mathcal{C} dans \\mathcal{B} pour former P_{\\mathcal{B}}^{\\mathcal{C}}).\n\nFormule du changement de base pour une application linéaire. Soient E une application linéaire et, \\mathcal{B} et \\mathcal{C}, deux bases de E. Alors\\begin{aligned}  \n   Mat_{\\mathcal{C}}(f)=P_{\\mathcal{C}}^{\\mathcal{B}} Mat_{\\mathcal{B}}(f)P_{\\mathcal{B}}^{\\mathcal{C}}, \n\\end{aligned}\n\n ou encore\\begin{aligned}  \n    Mat_{\\mathcal{C}}(f)=(P_{\\mathcal{B}}^{\\mathcal{C}})^{-1} Mat_{\\mathcal{B}}(f)P_{\\mathcal{B}}^{\\mathcal{C}}.\n\\end{aligned}\n\nDiagonalisation et décomposition en valeurs singulières.\n\nDiagonalisation. Soit \\mathbf{A} une matrice carrée à coefficients dans \\mathbb{K}=\\mathbb{R} \\text{ ou } \\mathbb{C}. On dit que \\mathbf{A} est diagonalisable s’il existe une matrice inversible \\mathbf{P} et une matrice diagonale \\mathbf{D} telles que \\mathbf{A} = \\mathbf{P}\\mathbf{D}\\mathbf{P}^{-1}. On dit aussi que \\mathbf{A} est similaire à \\mathbf{D}.\n\nImportant. Soient E un espace vectoriel de dimension finie et f un endomorphisme de E de matrice représentative (dans une base \\mathcal{B} de E) diagonalisable \\mathbf{A}=\\mathbf{P}\\mathbf{D}\\mathbf{P}^{-1}. On rappelle que les colonnes de \\mathbf{P} sont les vecteurs propres de \\mathbf{A}. Alors ces colonnes (dans leur ordre) constituent une base de E, et dans cette base, la matrice \\mathbf{A} est représentée par la matrice diagonale \\mathbf{D}. En d’autres termes, si \\mathcal{C} est la base des vecteurs propres de \\mathbf{A}, alors Mat_{\\mathcal{C}}(f)=\\mathbf{D}. Enfin, la matrice \\mathbf{D} est constituée des valeurs propres de \\mathbf{A} et le processus de calcul de \\mathbf{P} et \\mathbf{D} est appelé diagonalisation.\n\nDécomposition en valeurs singulières. Soit \\mathbf{M} une matrice de taille m\\times n et à coefficients dans \\mathbb{K}=\\mathbb{R} \\text{ ou } \\mathbb{C}. Alors \\mathbf{M} admet une factorisation de la forme \\mathbf{M}=\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V}^*, où\n\n\\mathbf{U} est une matrice unitaire (sur \\mathbb{K}) de taille m\\times m.\n\n\\mathbf{V}^* est l’adjoint (conjugué de la transposée) de \\mathbf{V}, matrice unitaire (sur \\mathbb{K}) de taille n\\times n\n\n\\mathbf{\\Sigma} est une matrice de taille m\\times n dont les coefficients diagonaux sont les valeurs singulières de \\mathbf{M}, i.e, les racines carrées des valeurs propres de \\mathbf{M}^*\\mathbf{M} et tous les autres coefficients sont nuls.\n\nCette factorisation est appelée la décomposition en valeurs singulières de \\mathbf{M}. Important. Si la matrice \\mathbf{M} est de rang r, alors\n\nles r premières colonnes de \\mathbf{U} sont les vecteurs singuliers à gauche de \\mathbf{M}\n\nles r premières colonnes de \\mathbf{V} sont les vecteurs singuliers à droite de \\mathbf{M}\n\nles r premiers coefficients strictement positifs de la diagonale de \\mathbf{\\Sigma} sont les valeurs singulières de \\mathbf{M} et tous les autres coefficients sont nuls.\n\nProduit scalaire et normes vectorielles. Soit V un espace vectoriel sur \\mathbb{R}. On appelle produit scalaire sur V toute application\\begin{aligned}\n  &\\langle \\cdot,\\cdot \\rangle &: V \\times V \\to \\mathbb{R} \\\\\n  &(\\mathbf{u},\\mathbf{v}) &\\mapsto \\langle \\mathbf{u},\\mathbf{v} \\rangle\n\\end{aligned}\n\n\\text{telle que,} \\forall (\\lambda_1, \\lambda_2, \\mathbf{u}, \\mathbf{v}, \\mathbf{w}) \\in \\mathbb{R}\\times\\mathbb{R}\\times V\\times V \\times V,\n\n\\langle\\mathbf{u},\\mathbf{v}\\rangle = \\langle\\mathbf{v},\\mathbf{u}\\rangle \\quad \\text{ (symétrie)}\n\nlinéarité:\n\n\\langle\\lambda_1 \\mathbf{u}+\\lambda_2\\mathbf{v}, \\mathbf{w}\\rangle = \\lambda_1 \\langle\\mathbf{u}, \\mathbf{w} \\rangle+\\lambda_2\\langle\\mathbf{v}, \\mathbf{w} \\rangle \\text{ (linéarité à gauche)}\n\n\\langle\\mathbf{u}, \\lambda_1 \\mathbf{v} + \\lambda_2 \\mathbf{w}\\rangle = \\lambda_1 \\langle\\mathbf{u}, \\mathbf{v} \\rangle+\\lambda_2\\langle\\mathbf{u}, \\mathbf{w} \\rangle \\text{ (linéarité à droite)}\n\n\\langle\\mathbf{u}, \\mathbf{u}\\rangle\\ge 0 \\text{ (positive)}\n\n\\langle\\mathbf{u}, \\mathbf{u}\\rangle=0 \\Longrightarrow \\mathbf{u}=0 \\text{(définie)}\n\nUne application\\begin{aligned}\n    \\|.\\|: \\quad&V\\rightarrow{\\mathbb{R_{+}}}\\\\\n    &\\mathbf{v}\\mapsto \\|\\mathbf{v}\\|\n\\end{aligned}\n\nest appelée norme sur V si \\forall\\ (\\lambda, \\mathbf{u}, \\mathbf{v})\\in \\mathbb{R}\\times V\\times V\n\n\\|\\lambda \\mathbf{u}\\|=|\\lambda|\\times \\|\\mathbf{u}\\|\n\n\\|\\mathbf{u}+\\mathbf{v}\\|\\le \\|\\mathbf{u}\\|+\\|\\mathbf{v}\\| (inégalité triangulaire)\n\nRemarque 2. Si \\langle.,.\\rangle est un produit scalaire sur V, alors \\langle.,.\\rangle induit une norme sur V. En effet,\\begin{aligned}\n    \\|.\\|_{\\langle.,.\\rangle}:\\quad&V\\rightarrow{\\mathbb{R_{+}}}\\\\\n    & \\mathbf{u}\\mapsto \\|\\mathbf{u}\\|=\\sqrt{\\langle\\mathbf{u},\\mathbf{u}\\rangle}\n\\end{aligned}\n\nExemples de normes et produits scalaires.Prenons V=\\mathbb{R}^n.\\bullet Les applications\\begin{aligned}\n    \\rho:\\quad &V\\times V\\rightarrow{\\mathbb{R}}\\\\\n    &(\\mathbf{u},\\mathbf{v})\\mapsto \\sum_{i=1}^{n}u_iv_i \n\\end{aligned}\n\net \\begin{aligned}\n    \\mu:\\quad &V\\rightarrow{\\mathbb{R}_+}\\\\\n    &\\mathbf{u}\\mapsto \\sqrt{\\sum_{i=1}^{n}u_i^2}\n\\end{aligned}\n\nsont respectivement un produit scalaire et une norme sur V.\n\nIl faut remarquer que \\forall \\mathbf{u} \\in V, \\quad \\mu(\\mathbf{u})=\\sqrt{\\rho(\\mathbf{u},\\mathbf{u})}.\n\n\\bullet Pour tout p\\in \\mathbb{N}^*, l’application\\begin{aligned}\n    \\mu_p:\\quad &V\\rightarrow{\\mathbb{R}_+}\\\\\n    &\\mathbf{u}\\mapsto \\left(\\sum_{i=1}^{n}|u_i|^p\\right)^{\\frac{1}{p}}\n\\end{aligned}\n\nest une norme sur V appelée norme p. Dans le cas p=2, on retrouve la norme \\mu ci-dessus appelée norme euclidienne.\n\nRemarque 3. Un espace vectoriel muni d’une norme est appelé espace vectoriel normé.\n\nNotion de distance. Soit E un ensemble non vide. Toute application d:~ E\\times E \\rightarrow\\mathbb{R}_+ qui satisfait pour tout x, y, z \\in E:\\begin{aligned}\n    &d(x,y) = d(y,x) \\text{ (symétrie)}\\\\\n    &d(x,y) = 0 \\implies x=y\\text{ (séparation)}\\\\\n    &d(x,y) \\le d(x,z)+d(z,y) \\text{ (inégalité triangulaire)}\n\\end{aligned}","type":"content","url":"/chapter2#alg-bre-lin-aire-et-analyse","position":11},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Exemples de distances.","lvl3":"Algèbre linéaire et Analyse","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#exemples-de-distances","position":12},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Exemples de distances.","lvl3":"Algèbre linéaire et Analyse","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"\\bullet\\begin{align}\n    d:\\quad &\\mathbb{R}^n\\times \\mathbb{R}^{n}\\rightarrow{\\mathbb{R}_+}\\nonumber\\\\\n    &(\\mathbf{u}, \\mathbf{v})\\mapsto \\left(\\sum_{i=1}^{n}|u_i-v_i|\\right).\n    \n\\end{align}\n\n\\bullet Distance Euclidienne. Elle est définie sur l’espace vectoriel \\mathbb{R}^n par\\begin{align}\n    d:\\quad &\\mathbb{R}^n\\times \\mathbb{R}^n\\rightarrow{\\mathbb{R}_+}\\nonumber \\\\\n    &(\\mathbf{u}, \\mathbf{v})\\mapsto \\left(\\sum_{i=1}^{n}|u_i-v_i|^2\\right)^{\\frac{1}{2}}.\n    \n\\end{align}\n\n\\bullet Distance de Minkowski.\n\nC’est la généralisation de la distance euclidienne et de la distance de Manhattan \\begin{align}\n    d_{Minkowski}:\\quad &\\mathbb{R}^n\\times \\mathbb{R}^n\\rightarrow{\\mathbb{R}_+}\\nonumber \\\\\n    &(\\mathbf{u}, \\mathbf{v})\\mapsto \\left(\\sum_{i=1}^{n}|u_i-v_i|^p\\right)^{\\frac{1}{p}}, p\\ge 1.\n    \n\\end{align}\n\n Espaces métriques.Définition. Un espace métrique est un ensemble E muni d’une distance d; on écrit (E, d).Remarque 4. Tout espace vectoriel normé est un espace métrique.Suites dans un espace métrique.Soit (E,d) un espace métrique. On appelle suite (d’éléments de E) et on note (u_n)_{n\\in I} ou (u)_n une application:\\begin{aligned}\n    u: \\quad& I \\rightarrow E\\\\\n    & n \\mapsto u(n):=u_n\n\\end{aligned}\n\noù I est une partie infinie de \\mathbb{N}. On dit que la suite (u)_n converge vers u^*\\in E si pour tout \\epsilon>0 il existe N \\in \\mathbb{N} tels que:\\begin{aligned}\n    \\forall n\\in \\mathbb{N}, \\quad n>N \\Longrightarrow d(u_n, u^*) < \\epsilon\n\\end{aligned}\n\nEn d’autres termes, la suite (u)_n converge vers u^*\\in E si pour tout \\epsilon>0, il existe un entier N\\in \\mathbb{N} tel que pour tout n>N, u_n est contenu dans la boule \\mathcal{B}_{\\epsilon} centrée en u^* et de rayon \\epsilon.\n\nNB: La suite (u)_n à valeurs dans E peut converger dans un ensemble autre que E.Définition. La suite (u)_n d’éléments de E est dite de Cauchy si pour tout \\epsilon>0, il existe N\\in\\mathbb{N} tel que:\\begin{aligned}\n    \\forall n>m \\in \\mathbb{N},\\quad m>N \\Longrightarrow d(u_n, u_m)<\\epsilon.\n\\end{aligned}\n\nAutrement dit, tous les termes u_n, u_m d’une suite de Cauchy se rapprochent de plus en plus lorsque n et m sont suffisamment grands.Espace métriques complets.Définition. Un espace métrique (E,d) est dit complet si toute suite de Cauchy de E converge dans E.Un espace métrique complet est appelé espace de Banach.","type":"content","url":"/chapter2#exemples-de-distances","position":13},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Calcul du gradient (dérivation).","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl3","url":"/chapter2#calcul-du-gradient-d-rivation","position":14},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Calcul du gradient (dérivation).","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Fonction réelle.\n\nDéfinition. Soit f: J\\rightarrow \\mathbb{R} une fonction, avec J un intervalle ouvert de \\mathbb{R}.On dit que f est dérivable en a\\in J si la limite:\\begin{aligned}\n    \\lim_{h\\rightarrow 0} \\frac{f(a+h)-f(a)}{h} \\text{ est finie.}\n\\end{aligned}\n\nSi f est dérivable en a, la dérivée de f en a est notée f'(a). La fonction dérivée de f est notée f' ou \\frac{\\mathrm{d}f}{\\mathrm{d}x} ou \\mathrm{d}f.Exemple de dérivées.\n\nFonctions polynomiales.La dérivée de la fonction f(x)=a_nx^n+a_{n-1}x^{n-1}+\\dots + a_1x+a_0, avec les a_i des constantes, est f'(x)=na_nx^{n-1}+(n-1)a_{n-1}x^{n-2}+\\dots+a_1.\n\nFonction exponentielle de base e.La dérivée de la fonction f(x)=\\exp(x) est la fonction f elle-même, i.e, \\frac{\\mathrm{d}\\exp}{\\mathrm{d}x}(x)=\\exp(x).\n\nFonctions trigonométriques.\\frac{\\mathrm{d}\\cos}{\\mathrm{d}x}( x)=-\\sin x et \\frac{\\mathrm{d} \\sin}{dx}(x)=\\cos x.\n\nFonction logarithme népérien.\\frac{\\mathrm{d} \\ln}{\\mathrm{d}x}  (x) = \\frac{1}{x}.\n\nPropriétés. Soient J\\subseteq \\mathbb{R} un intervalle ouvert, u,\\ v\\ : J\\rightarrow \\mathbb{R} deux fonctions et \\lambda \\in \\mathbb{R}. Alors on a les propriétés suivantes de la dérivée:\n\n(u+v)' = u'+v'\n\n(uv)' = uv'+u'v\n\n(\\lambda u)' = \\lambda u'\n\nCes propriétés s’étendent aux fonctions vectorielles en dimension supérieure.\n\nFonctions vectorielles. Soit f: \\mathcal{O}\\rightarrow \\mathbb{R}^p une fonction, avec \\mathcal{O} une partie ouverte de \\mathbb{R}^n, n, p\\ge 1. On dit que f est différentiable (au sens de Fréchet) en \\mathbf{a}\\in \\mathcal{O}, s’il existe une application linéaire continue L: \\mathbb{R}^n\\rightarrow \\mathbb{R}^p telle que pour tout h\\in \\mathbb{R}^n, on a\\begin{aligned}\n    \\lim_{h\\rightarrow 0} \\frac{f(\\mathbf{a}+h)-f(\\mathbf{a})-L(h)}{\\|h\\|}=0.\n\\end{aligned}\n\n Si f est différentiable en tout point de \\mathcal{O}, on dit que f est différentiable sur \\mathcal{O}.La différentielle de f est notée Df.Dérivées partielles.Soient \\mathbf{a}=\\begin{bmatrix}\na_1\\\\ a_2\\\\ \\vdots \\\\ a_n\n\\end{bmatrix}\\in \\mathcal{O}\\subseteq{\\mathbb{R}^n} et f: \\mathcal{O}\\rightarrow \\mathbb{R}^p une fonction.\n\nOn dit que f admet une dérivée partielle par rapport à la j-ème variable x_j si la limite:\\begin{aligned} \n    \\lim_{h\\rightarrow 0}\\frac{f(a_1, a_2, \\dots, a_j+h, \\dots, a_n)-f(\\mathbf{a})}{h} \\text{ est finie.}\n\\end{aligned}\n\nLa dérivée partielle par rapport à la variable x_j de f en \\mathbf{a} est notée \\frac{\\partial f}{\\partial x_j}(\\mathbf{a}).Note. Si f est différentiable, alors f admet des dérivées partielles par rapport à toutes les variables.Gradient et Matrice Jacobienne. Soit f: \\mathcal{O}\\subseteq\\mathbb{R}^n \\rightarrow \\mathbb{R}^p une fonction différentiable.On suppose que les fonctions composantes de f sont f_1, f_2, \\dots, f_p.Alors la matrice des dérivées partielles \\begin{bmatrix}\n\\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} &\\dots & \\frac{\\partial f_1}{\\partial x_n}\\\\[0.2cm]\n\\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} &\\dots & \\frac{\\partial f_2}{\\partial x_n}\\\\\n\\vdots&\\vdots& & \\vdots\\\\\n\\frac{\\partial f_p}{\\partial x_1} & \\frac{\\partial f_p}{\\partial x_2} &\\dots & \\frac{\\partial f_p}{\\partial x_n}\n\\end{bmatrix}\n\n est appelée la matrice jacobienne de f, notée \\mathbf{J}_f ou \\mathbf{J}(f).Dans le cas p=1, le vecteur \\begin{bmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\[0.2cm] \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n}\n\\end{bmatrix} est appelé \\operatorname{\\mathbf{gradient}} de f et noté \\mathbf{\\nabla} f ou \\operatorname{\\mathbf{grad}}(f).Exemples du calcul de dérivées et de gradients sur \\mathbb{R}^n.\n\nf(\\mathbf{x})=\\langle\\mathbf{x},\\mathbf{x}\\rangle=\\mathbf{x}^T\\mathbf{x}. Le gradient de f est \\nabla f(\\mathbf{x})=2\\mathbf{x}\n\nf(\\mathbf{x})=\\mathbf{A}\\mathbf{x}+\\mathbf{b}, avec \\mathbf{A} une matrice et \\mathbf{b} un vecteur. On a Df(\\mathbf{x})=\\mathbf{A}.","type":"content","url":"/chapter2#calcul-du-gradient-d-rivation","position":15},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Dérivées de fonctions composées.","lvl3":"Calcul du gradient (dérivation).","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#d-riv-es-de-fonctions-compos-es","position":16},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Dérivées de fonctions composées.","lvl3":"Calcul du gradient (dérivation).","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Il existe souvent des fonctions dont le gradient ne peut facilement être calculé en utilisant les formules précédentes. Pour trouver le gradient d’une telle fonction, on va réécrire la fonction comme étant une composition de fonctions dont le gradient est facile à calculer en utilisant les techniques que nous allons introduire. Dans cette partie nous allons présenter trois formules de dérivation de fonctions composées.\n\nComposition de fonctions à une seule variable. Soit f,g,h: \\mathbb{R}\\rightarrow\\mathbb{R}, trois fonctions réelles telles que f(x) = g(h(x)). \\begin{aligned}  \n    \\frac{\\mathrm{d} f}{\\mathrm{d} x} = \\frac{\\mathrm{d} g}{\\mathrm{d} h}\\frac{\\mathrm{d} h}{\\mathrm{d} x}    \n\\end{aligned}\n\nFormule de dérivée totale. Soit f:\\mathbb{R}^{n+1}\\rightarrow\\mathbb{R} telle que f = f(x,u_1(x),\\dots,u_n(x)) avec u_i:\\mathbb{R}\\rightarrow\\mathbb{R} alors\\begin{aligned}  \n    \\frac{\\mathrm{d} f\\left(x, u_{1}, \\ldots, u_{n}\\right)}{\\mathrm{d} x}=\\frac{\\partial f}{\\partial x}+\\frac{\\partial f}{\\partial u_{1}} \\frac{\\mathrm{d} u_{1}}{\\mathrm{d} x}+\\frac{\\partial f}{\\partial u_{2}} \\frac{\\mathrm{d} u_{2}}{\\mathrm{d} x}+\\ldots+\\frac{\\partial f}{\\partial u_{n}} \\frac{\\mathrm{d} u_{n}}{\\mathrm{d} x}=\\frac{\\partial f}{\\partial x}+\\sum_{i=1}^{n} \\frac{\\partial f}{\\partial u_{i}} \\frac{\\mathrm{d} u_{i}}{\\mathrm{d} x}.    \n\\end{aligned}\n\nFormule générale de dérivées de fonctions composées. Soit\\begin{aligned} \n    \\begin{array}{l}\nf :\\mathbb{R}^{k} \\rightarrow\\mathbb{R}^{m} \\\\\n\\mathbf{x} \\mapsto f(\\mathbf{x})\n\\end{array}\n\\begin{array}{l}\ng :\\mathbb{R}^{n} \\rightarrow\\mathbb{R}^{k} \\\\\n\\mathbf{x} \\mapsto g(\\mathbf{x})\n\\end{array}    \n\\end{aligned}\n\noù \\mathbf{x}=(x_1,\\dots,x_n) , f(\\mathbf{x}) = (f_1(\\mathbf{x}),\\dots,f_m(\\mathbf{x})) et g(\\mathbf{x}) = (g_1(x),\\dots,g_k(x)).\n\nLe gradient de f(g(\\mathbf{x})) est défini comme suit:\\begin{aligned}  \n    \\frac{\\partial}{\\partial \\mathbf{x}} \\mathbf{f}(\\mathbf{g}(\\mathbf{x}))=\\left[\\begin{array}{cccc}\n\\frac{\\partial f_{1}}{\\partial g_{1}} & \\frac{\\partial f_{1}}{\\partial g_{2}} & \\ldots & \\frac{\\partial f_{1}}{\\partial g_{k}} \\\\\n\\frac{\\partial f_{2}}{\\partial g_{1}} & \\frac{\\partial f_{2}}{\\partial g_{2}} & \\cdots & \\frac{\\partial f_{2}}{\\partial g_{k}} \\\\\n\\vdots &\\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial f_{m}}{\\partial g_{1}} & \\frac{\\partial f_{m}}{\\partial g_{2}} & \\ldots & \\frac{\\partial f_{m}}{\\partial g_{k}}\n\\end{array}\\right]\\left[\\begin{array}{cccc}\n\\frac{\\partial g_{1}}{\\partial x_{1}} & \\frac{\\partial g_{1}}{\\partial x_{2}} & \\ldots & \\frac{\\partial g_{1}}{\\partial x_{n}} \\\\\n\\frac{\\partial g_{2}}{\\partial x_{1}} & \\frac{\\partial g_{2}}{\\partial x_{2}} & \\cdots & \\frac{\\partial g_{2}}{\\partial x_{n}} \\\\\n\\vdots &\\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial g_{k}}{\\partial x_{1}} & \\frac{\\partial g_{k}}{\\partial x_{2}} & \\cdots & \\frac{\\partial g_{k}}{\\partial x_{n}}\n\\end{array}\\right]\n\\end{aligned}","type":"content","url":"/chapter2#d-riv-es-de-fonctions-compos-es","position":17},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl3","url":"/chapter2#probabilit-s","position":18},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"La théorie des probabilités constitue un outil fondamental dans l’apprentissage automatique. Les probabilités vont nous servir à modéliser une expérience aléatoire, c’est-à-dire un phénomène dont on ne peut pas prédire l’issue avec certitude, et pour lequel on décide que le dénouement sera le fait du hasard.Définition.Une probabilité est une application sur \\mathcal{P}(\\Omega), l’ensemble des parties de \\Omega telle que:\n\n0 \\leq \\operatorname{\\mathbb{P}}(A) \\leq 1, pour tout événement A \\subseteq \\Omega;\n\n\\operatorname{\\mathbb{P}}(A)=\\sum_{\\{\\omega\\} \\in A} \\operatorname{\\mathbb{P}}(\\omega), pour tout événement A;\n\n\\operatorname{\\mathbb{P}}(\\Omega)=\\sum_{A_{i}} \\operatorname{\\mathbb{P}}(A_{i})=1, avec les A_{i} \\subseteq \\Omega une partition de \\Omega.\n\nProposition. Soient A et B deux événements,\n\n\\operatorname{Si} A et B sont incompatibles, \\operatorname{\\mathbb{P}}(A \\cup B)=\\operatorname{\\mathbb{P}}(A)+\\operatorname{\\mathbb{P}}(B).\n\n\\operatorname{\\mathbb{P}}\\left(A^{c}\\right)=1-\\operatorname{\\mathbb{P}}(A), avec A^{c} le complémentaire de A.\n\n\\operatorname{\\mathbb{P}}(\\emptyset)=0.\n\n\\operatorname{\\mathbb{P}}(A \\cup B)=\\operatorname{\\mathbb{P}}(A)+\\operatorname{\\mathbb{P}}(B)-\\operatorname{\\mathbb{P}}(A \\cap B).\n\nPreuve voir [\n\nPardoux (2015)]Ci-dessous une définition plus générale de probabilité, valable pour des espaces des événements possibles non dénombrables.Définition. Soit A une expérience alátoire et \\Omega l’espace des événements possibles associés. Une probabilité sur \\Omega est une application définie sur l’ensemble des événements, qui vérifie:\n\nAxiome 1: 0\\leq \\operatorname{\\mathbb{P}}(A)\\leq 1, pour tout événement A;\n\nAxiome 2: Pour toute suite d’événements (A_i)_{i\\in \\operatorname{\\mathbf{N}}}, deux à deux incompatibles,\\begin{aligned}  \n              \\operatorname{\\mathbb{P}}\\left(\\bigcup_{i \\in \\operatorname{\\mathbf{N}}} A_{i}\\right)=\\sum_{i \\in \\operatorname{\\mathbf{N}}} \\operatorname{\\mathbb{P}}\\left(A_{i}\\right);    \n          \\end{aligned}\n\nAxiome 3: \\operatorname{\\mathbb{P}}(\\Omega) = 1.\n\n\\mathrm{NB}: Les événements \\left(A_{i}\\right)_{i \\in \\operatorname{\\mathbf{N}}} sont deux à deux incompatibles, si pour tous i \\neq j, A_{i} \\cap A_{j}=\\emptyset.","type":"content","url":"/chapter2#probabilit-s","position":19},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Indépendance et conditionnement.","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#ind-pendance-et-conditionnement","position":20},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Indépendance et conditionnement.","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Motivation. Quelle est la probablité d’avoir un cancer du poumon?\n\nInformation supplémentaire: vous fumez une vingtaine de cigarettes par jour. Cette information va changer la probabilité.\n\nL’outil qui permet cette mise à jour est la probabilité conditionnelle.\n\nDéfinition.Étant donnés deux événements A et B, avec \\operatorname{\\mathbb{P}}(A) > 0, on appelle probabilité de B conditionnellement à A, ou sachant A, la probabilité notée \\operatorname{\\mathbb{P}}(B \\mid A) définie par: \\operatorname{\\mathbb{P}}(B \\mid A)=\\frac{\\operatorname{\\mathbb{P}}(A \\cap B)}{\\mathbb{P}(A)}.\n\nL’équation \n\n(36) peut aussi s’écrire comme \\mathbb{P}(A \\cap B)=\\mathbb{P}(B \\mid A) \\mathbb{P}(A).De plus, la probabilité conditionnelle sachant A, notée \\mathbb{P}(. \\mid A) est une nouvelle probabilité et possède toutes les propriétés d’une probabilité.\n\nProposition. (Formule des probabilités totales généralisée)Soit (A_i)_{i\\in I} (I un ensemble fini d’indices) une partition de \\Omega telle que 0 < \\mathbb{P}(A_i)\\leq 1 \\quad\\forall i\\in I. Pour tout événement B, on a \\begin{aligned}  \n    \\mathbb{P}(B)=\\sum_{i \\in I} \\mathbb{P}\\left(B|A_{i}\\right)\\mathbb{P}\\left(A_{i}\\right).\n\\end{aligned}\n\nLa formule des probabilités totales permet de servir les étapes de l’expérience aléatoire dans l’ordre chronologique.\n\nProposition. (Formule de Bayes généralisée)Soit (A_i)_{i\\in I} une partition de \\Omega tel que 0\\leq \\mathbb{P}(A_{i})\\leq 1,\\forall i\\in I. Soit un événement B, tel que \\mathbb{P}(B)>0. Alors pour tout i\\in I,\\mathbb{P}(A_{i}|B)=\\frac{ \\mathbb{P}\\left(B|A_{i}\\right)\\mathbb{P}\\left(A_{i}\\right)}{\\sum_{i \\in I} \\mathbb{P}\\left(B|A_{i}\\right)\\mathbb{P}\\left(A_{i}\\right)}.\n\nDéfinition.\n\nDeux événements A et B sont dits indépendants si\\begin{aligned}  \n  \\mathbb{P}(A\\cap B) = \\mathbb{P}(A)\\mathbb{P}(B).  \n\\end{aligned}\n\nS’ils sont de probabilité non nulle, alors\\begin{aligned}  \n    \\mathbb{P}(B|A) = \\mathbb{P}(B) \\Leftrightarrow \\mathbb{P}(A|B) = \\mathbb{P}(A) \\Leftrightarrow \\mathbb{P}(A\\cap B) = \\mathbb{P}(A)\\mathbb{P}(B).    \n\\end{aligned}","type":"content","url":"/chapter2#ind-pendance-et-conditionnement","position":21},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Variables aléatoires.","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#variables-al-atoires","position":22},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Variables aléatoires.","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Définition. Une variable aléatoire (v.a) X est une fonction définie sur l’espace fondamental \\Omega, qui associe une valeur numérique à chaque résultat de l’expérience aléatoire étudiée. Ainsi, à chaque événement élémentaire \\omega, on associe un nombre X(\\omega).\n\nUne variable qui ne prend qu’un nombre dénombrable de valeurs est dite discrète (par exemple le résultat d’une lancée d’une pièce de monnaie, ...), sinon, elle est dite continue (par exemple le prix d’un produit sur le marché au fil du temps, distance de freinage d’une voiture roulant à 100 km/h).","type":"content","url":"/chapter2#variables-al-atoires","position":23},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Variable aléatoire discrète","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#variable-al-atoire-discr-te","position":24},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Variable aléatoire discrète","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Définition. L’espérance mathématique ou moyenne d’une v.a discrète X est le réel\\begin{aligned}  \n   \\mathbb{E}[X] = \\sum_{k=0}^{\\infty} k \\mathbb{P}[X = k]. \n\\end{aligned}\n\nPour toute fonction g, \\begin{aligned}  \n    \\mathbb{E}[g(X)] = \\sum_{k=0}^{\\infty} g(k) \\mathbb{P}[X = k].\n\\end{aligned}\n\nDéfinition. La variance d’une v.a discrète X est le réel positif\\begin{aligned}  \n    Var[X] = \\mathbb{E}\\left[(X-\\mathbb{E}[X])^2\\right] = \\sum_{k=0}^{\\infty} \\left(k-\\mathbb{E}[X]\\right)^2 \\mathbb{P}[X = k] = \\mathbb{E}[X^2] -\n\\mathbb{E}[X]^2    \n\\end{aligned}\n\net l’écart-type de X est la racine carrée de sa variance.\n\nExemple: (Loi de Bernoulli) La loi de Bernoulli est fondamentale pour la modélisation des problèmes de classification binaire en apprentissage automatique. On étudie que les expériences aléatoires qui n’ont que deux issues possibles (succès ou échec). Une expérience aléatoire de ce type est appelée une épreuve de Bernoulli. Elle se conclut par un succès si l’évènement auquel on s’intéresse est réalisé ou un échec sinon. On associe à cette épreuve une variable aléatoire Y qui prend la valeur 1 si l’évènement est réalisé et la valeur 0 sinon. Cette v.a. ne prend donc que deux valeurs (0 et 1) et sa loi est donnée par :\\begin{aligned}  \n    \\mathbb{P}[Y=1]=p, \\quad \\mathbb{P}[Y=0]=q=1-p.\\qquad \\operatorname{Avec } p \\in [0, 1].    \n\\end{aligned}\n\nOn dit alors que Y suit une loi de Bernoulli de paramètre p, notée \\mathcal{B}(p). La v.a. Y a pour espérance p et pour variance p(1-p) .\n\nEn effet,\\begin{aligned}  \n    \\mathbb{E}[Y]=0 \\times(1-p)+1 \\times p=p    \n\\end{aligned}\n\net\\begin{aligned}  \n    \\operatorname{Var}(Y)=\\mathbb{E}\\left[Y^{2}\\right]-\\mathbb{E}[Y]^{2}=\\mathbb{E}[Y]-\\mathbb{E}[Y]^{2}=p(1-p).\n\\end{aligned}\n\nSchéma de Bernoulli:\n\nChaque épreuve a deux issues : succès [S] ou échec [E].\n\nPour chaque épreuve, la probabilité d’un succès est la même, notons \\mathbb{P}(S) = p et \\mathbb{P}(E) = q = 1 - p.\n\nLes n épreuves sont indépendantes : la probabilité d’un succès ne varie pas, elle ne dépend pas des informations sur les résultats des autres épreuves.","type":"content","url":"/chapter2#variable-al-atoire-discr-te","position":25},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Variable aléatoire continue","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#variable-al-atoire-continue","position":26},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Variable aléatoire continue","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Contrairement aux v.a. discrètes, les v.a. continues sont utilisées pour mesurer des grandeurs \"continues\" (comme distance, masse, pression...). Une variable aléatoire continue est souvent définie par sa densité de probabilité ou simplement densité. Une densité f décrit la loi d’une v.a X en ce sens: \\forall a,b \\in \\mathbb{R}, \\quad \\mathbb{P}[a\\leq X \\leq b] = \\int_{a}^{b} f(x)dx\n\n et \\forall x\\in \\mathbb{R}, \\quad F(x) = \\mathbb{P}[X\\leq x] =  \\int_{-\\infty}^{x} f(t)dt\n\n . On en déduit qu’une densité doit vérifier \\forall x\\in \\mathbb{R}, \\quad f(x)\\geq 0 \\text{ et } \\int_{\\mathbb{R}}^{} f(x)dx = 1\n\n .\n\nDéfinition. On appelle densité de probabilité toute fonction réelle positive, d’intégrale 1.\n\nDéfinition. L’espérance mathématiques de la v.a X est définie par \\mathbb{E}[X]=\\int_{\\mathbb{R}}^{} xf(x)dx.\n\nExemple.\n\nLa loi normale C’est la loi de probabilité la plus importante. Son rôle est central dans de nombreux modèles probabilistes et en statistique. Elle possède des propriétés intéressantes qui la rendent agréable à utiliser. La densité d’une variable aléatoire suivant la loi normale de moyenne \\mu et d’écart-type \\sigma (\\mathcal{N}(\\mu,\\sigma^2)) est définie par f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right), \\quad \\forall x \\in \\mathbb{R}.\n\n Quand \\mu=0 \\quad \\text{et} \\quad \\sigma = 1, on parle de loi normale centrée et réduite.","type":"content","url":"/chapter2#variable-al-atoire-continue","position":27},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Loi des grands nombres","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#loi-des-grands-nombres","position":28},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Loi des grands nombres","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Considérons une suite \\left(X_{n}\\right)_{n \\geq 1} de v.a. indépendantes et de même loi. Supposons que ces v.a. ont une espérance, m et une variance, \\sigma^{2}.\n\nThéorème.\\mathbb{E}\\left[\\sum_{i=1}^{n} X_i\\right] = nm\n\n \\operatorname{Var}\\left[\\sum_{i=1}^{n} X_i\\right] = n\\sigma^2\n\nDéfinition. La moyenne empirique des v.a. X_1,\\dots,X_n est la v.a. \\bar{X_n} = \\frac{X_1+\\dots + X_n}{n}.\n\n On sait d’ores et déjà que la moyenne empirique a pour espérance m et pour variance \\frac{\\sigma^2}{n}. Ainsi, plus n est grand, moins cette v.a. varie. A la limite, quand n tend vers l’infini, elle se concentre sur son espérance, m. C’est la loi des grands nombres.\n\nThéorème. (Convergence en Probabilité) Quand n est grand, \\bar{X_n} est proche de m avec une forte probabilité. Autrement dit, \\forall \\varepsilon \\ge 0, \\quad \n    \\lim\\limits_{n\\to\\infty} \\mathbb{P}(|\\bar{X_n}-m|> \\varepsilon) = 0.\n\n Théorème central limite\n\nLe Théorème central limite est très important en apprentissage automatique. Il est souvent utilisé pour la transformation des données surtout au traitement de données aberrantes.\n\nThéorème. Pour tous réels a<b, quand n tend vers +\\infty, \\mathbb{P}\\left(a \\leq \\frac{\\bar{X}_{n}-m}{\\sigma / \\sqrt{n}} \\leq b\\right) \\longrightarrow \\int_{a}^{b} \\frac{1}{\\sqrt{2 \\pi}} e^{-x^{2} / 2} \\mathrm{d} x.\n\n On dit que \\displaystyle \\frac{\\bar{X}_{n}-m}{\\sigma / \\sqrt{n}} converge en loi vers la loi normale \\mathcal{N}(0,1).","type":"content","url":"/chapter2#loi-des-grands-nombres","position":29},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Intervalles de confiance","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#intervalles-de-confiance","position":30},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Intervalles de confiance","lvl3":"Probabilités","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Soit X un caractère (ou variable) étudié sur une population, de moyenne m et de variance \\sigma^2. On cherche ici à donner une estimation de la moyenne m de ce caractère, calculée à partir de valeurs observées sur un échantillon (X_1, ..., X_n). La fonction de l’échantillon qui estimera un paramètre est appelée estimateur, son écart-type est appelé erreur standard et est noté SE. L’estimateur de la moyenne m est la moyenne empirique: \\frac{1}{n}\\sum_{i=1}^{n} X_i\n\n D’après les propriétés de la loi normale, avec un erreur \\alpha = 5\\% quand n est grand on sait que\\begin{aligned}     \n    \\mathbb{P}\\left[m-2\\sigma/ \\sqrt{n}\\leq \\bar{X_n}\\leq m+2\\sigma/ \\sqrt{n}\\right] = 1- \\alpha =  0.954\n\\end{aligned}\n\nou, de manière équivalente,\\begin{aligned}      \n    \\mathbb{P}\\left[\\bar{X_n}-2\\sigma/ \\sqrt{n}\\leq m\\leq \\bar{X_n}+2\\sigma/ \\sqrt{n}\\right] = 1- \\alpha = 0.954\n\\end{aligned}\n\nCe qui peut se traduire ainsi: quand on estime m par \\bar{X_n}, l’erreur faite est inférieure à 2\\sigma/ \\sqrt{n}, pour 95,4\\% des échantillons. Ou avec une probabilité de 95,4\\%, la moyenne inconnue m est dans l’intervalle \\left[\\bar{X_n}-2\\sigma/ \\sqrt{n},\\ \\bar{X_n}+2\\sigma/ \\sqrt{n}\\right]. Voir [\n\nAnirban (2011)] pour plus d’explication.\n\nDéfinition. On peut associer à chaque incertitude \\alpha, un intervalle appelé intervalle de confiance de niveau de confiance 1 - \\alpha, qui contient la vraie moyenne m avec une probabilité égale à 1 - \\alpha.\n\nDéfinition. Soit Z une v.a.. Le fractile supérieur d’ordre \\alpha de la loi de Z est le réel z qui vérifie \\mathbb{P}\\left[Z\\geq z\\right] = \\alpha\n\n Le fractile inférieur d’ordre \\alpha de la loi Z est le réel z qui vérifie \\mathbb{P}\\left[Z\\leq z\\right] = \\alpha.\n\n Quand l’écart-type théorique de la loi du caractère X étudié n’est pas connu, on l’éstime par l’écart-type empirique s_{n-1}. Comme on dispose d’un grand échantillon, l’erreur commise est petite. L’intervalle de confiance, de niveau de confiance 1-\\alpha devient : \\left[\\bar{x}_{n}-z_{\\alpha / 2} \\frac{s_{n-1}}{\\sqrt{n}}, \\ \\bar{x}_{n}+z_{\\alpha / 2} \\frac{s_{n-1}}{\\sqrt{n}}\\right]\n\n où s_{n-1}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}.","type":"content","url":"/chapter2#intervalles-de-confiance","position":31},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Estimations paramétriques","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl3","url":"/chapter2#estimations-param-triques","position":32},{"hierarchy":{"lvl1":"Pré-requis","lvl3":"Estimations paramétriques","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Soit (\\Omega,\\mathcal{A},\\mathbf{P}) un espace probabilisé et \\mathbf{x} une v.a. de (\\Omega,\\mathcal{A}) dans (E,\\mathcal{E}). La donnée d’un modèle statistique c’est la donnée d’une famille de probabilités sur (E,\\mathcal{E}), \\{\\mathbb{P}_{\\theta},\\theta\\in\\Theta\\}. Le modèle étant donné, on suppose alors que la loi de \\mathbf{x} appartient au modèle \\{\\mathbf{P}_{\\theta},\\theta\\in\\Theta\\}. Par exemple dans le modèle de Bernoulli, \\mathbf{x} = (x_1,\\dots,x_n) où les x_i sont i.i.d. (indépendantes et identiquement distribuées) de loi de Bernoulli de paramètre \\theta\\in\\left]0,1\\right]. E = \\{0,1\\}^n, \\mathcal{E} = \\mathcal{P}(E), \\Theta = \\left]0,1\\right] et P_{\\theta}=\\left((1-\\theta) \\delta_{0}+\\theta \\delta_{1}\\right)^{\\otimes n}.\n\nDéfinition. On dit que le modèle \\left\\{\\mathbb{P}_{\\theta},\\theta\\in\\Theta\\right\\} est identifiable si l’application \\begin{array}{l}\n    \\Theta \\rightarrow\\left\\{P_{\\theta}, \\theta \\in \\Theta\\right\\} \\\\\n    \\theta \\mapsto P_{\\theta}\n\\end{array}\n\nest injective.\n\nDéfinition. Soit g:\\  \\Theta\\rightarrow\\mathbb{R}^k. On appelle estimateur de g(\\theta) au vu de l’observation x, toute application T : \\Omega\\rightarrow \\mathbb{R}^k de la forme T = h(x) où h : E\\mapsto\\mathbb{R}^k mesurable. Un estimateur ne doit pas dépendre de la quantité g(\\theta) que l’on cherche à estimer. On introduit les propriètés suivantes d’un estimateur.\n\nDéfinition. T est un estimateur sans biais de g(\\theta) si pour tout \\theta \\in\\Theta,\\quad \\mathbb{E}_{\\theta}[T] = g(\\theta).\n\nDans le cas contraire, on dit que l’estimateur T est biaisé et on appelle biais la quantité \\mathbb{E}_{\\theta}[T] - g(\\theta).\n\nGénéralement \\mathbf{x} est un vecteur \\left(x_{1}, \\ldots, x_{n}\\right) d’observations (n étant le nombre d’entre elles). Un exemple important est le cas où x_{1},\\ldots, x_{n} forme un n-échantillon c’est à dire lorsque que x_{1}, \\ldots, x_{n} sont i.i.d. On peut alors regarder des propriétés asymptotiques de l’estimateur, c’est-à-dire en faisant tendre le nombre d’observations n vers +\\infty. Dans ce cas, il est naturel de noter T = T_n comme dépendant de n. On a alors la définition suivante :\n\nDéfinition. T_n est un estimateur consistant de g(\\theta) si pour tout \\theta \\in \\Theta, T_n converge en probabilité vers g(\\theta) sous P_{\\theta} lorsque n\\to\\infty.\n\nOn définit le risque quadratique de l’estimateur dans le cas où g(\\theta)\\in\\mathbb{R}.\n\nDéfinition. Soit T_n un estimateur de g(\\theta). Le risque quadratique de T_n est défini par R(T_n,g(\\theta)) = \\mathbb{E}_{\\theta}[(T_n - g(\\theta))^2]","type":"content","url":"/chapter2#estimations-param-triques","position":33},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Estimation par la méthode des moments","lvl3":"Estimations paramétriques","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#estimation-par-la-m-thode-des-moments","position":34},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Estimation par la méthode des moments","lvl3":"Estimations paramétriques","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Considérons un échantillon \\mathbf{x} = (x_1,\\dots,x_n). Soit f = (f_1,\\dots,f_k) une application de \\mathcal{X} dans \\mathbb{R}^k tel que le modèle \\{\\mathbb{P}_{\\theta},\\theta\\in\\Theta\\} est identifiable si l’application \\Phi\\begin{array}{l}\n\\Phi: ~\\Theta \\rightarrow \\mathbb{R}^k \\\\\n\\quad ~~~\\theta \\mapsto \\Phi(\\theta) = \\mathbb{E}_{\\theta}[f(x)]\n\\end{array}\n\n est injective. On définit l’estimateur \\hat{\\theta}_n comme la solution dans \\Theta (quand elle existe) de l’équation\\mathbb{E}_{\\theta}[f(\\mathbf{x})]\\approx \\frac{1}{n}\\sum_{i=1}^{n} f(x_i).\n\nSouvent, lorsque \\mathcal{X}\\subset \\mathbb{R}, on prend f_i(x) = x^i et \\Phi correspond donc au ième moment de la variable de X_i sous \\mathbb{P}_{\\theta}. Ce choix justifie le nom donné à la méthode. Voici quelques exemples d’estimateurs bâtis sur cette méthode.\n\nExemple. (Loi uniforme)\n\nIci k=1, Q_{\\theta} est la loi uniforme sur [0,\\theta] avec \\theta > 0. On a pour tout \\theta, \\displaystyle \\mathbb{E}_{\\theta}[X_1] = \\frac{\\theta}{2}, on peut donc prendre par exemple \\displaystyle \\Phi(\\theta) = \\frac{\\theta}{2} et f(x) = x. L’estimateur obtenu par la méthode des moments est alors \\hat{\\theta}_n =2\\bar{X_n}. Cet estimateur est sans biais et constant.\n\nExemple. (Loi normale) Ici k=2, on prend Q_{\\theta} = \\mathcal{N}(m,\\sigma^2) avec \\theta = (m,\\sigma^2)\\in\\mathbb{R}\\times\\mathbb{R}_{+}^{*}. Pour tout \\theta, \\mathbb{E}_{\\theta}[X_1] = m et \\mathbb{E}_{\\theta}[X_1^2] = m^2 + \\sigma^2 , on peut donc prendre par exemple, f_1(x) = x et f_2(x) = x^2 ce qui donne \\Phi(m,\\ \\sigma^2) = (m,m^2+\\sigma^2). L’estimateur obtenu par la méthode des moments vérifie \\hat{m}_{n}=\\bar{X}_{n} \\text { et } \\hat{m}_{n}^{2}+\\hat{\\sigma}_{n}^2=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}^{2}\n\n c’est-à-dire \\hat{\\theta}_{n}=\\left(\\bar{X}_{n},\\ \\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}_{n}\\right)^{2}\\right)\n\n L’estimateur est consistant mais l’estimateur de la variance est biaisé.","type":"content","url":"/chapter2#estimation-par-la-m-thode-des-moments","position":35},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Estimation par maximum de vraisemblance","lvl3":"Estimations paramétriques","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"type":"lvl4","url":"/chapter2#estimation-par-maximum-de-vraisemblance","position":36},{"hierarchy":{"lvl1":"Pré-requis","lvl4":"Estimation par maximum de vraisemblance","lvl3":"Estimations paramétriques","lvl2":"Les Bases Mathématiques pour l’Apprentissage Automatique"},"content":"Soit \\{E,\\ \\mathcal{E},\\ \\{P_{\\theta},\\ \\theta\\in\\Theta\\}\\} un modèle statistique, où \\Theta\\subset\\mathbb{R}^k. On suppose qu’il existe une mesure \\sigma-finie \\mu qui domine le modèle, c’est à dire que \\forall \\theta\\in\\Theta, P_{\\theta} admet une densité par rapport à \\mu.\n\nDéfinition.Soit \\mathbf{x} une observation. On appelle vraisemblance de \\mathbf{x} l’application \\begin{array}{l}\n    \\Theta \\rightarrow\\mathbb{R}_+ \\\\\n    \\theta \\mapsto \\mathbb{P}(\\theta,\\ \\mathbf{x})\n    \\end{array}\n\nOn appelle estimateur du maximum de vraisemblance de \\theta, tout élément \\hat{\\theta} de \\Theta maximisant la vraisemblance, c’est à dire vérifiant\\hat{\\theta} = \\arg \\underset{\\theta\\in\\Theta}{\\max}\\  \\mathbf{P}(\\theta,\\ \\mathbf{x})\n\nConsidérons le cas typique où \\mathbf{x}=\\left(x_{1}, \\ldots, x_{n}\\right), les x_{i} formant un n-échantillon de loi Q_{\\theta_{0}} où Q_{\\theta_{0}} est une loi sur \\mathcal{X} de paramètre inconnu \\theta_{0} \\in \\Theta \\subset \\mathbb{R}^{k} . On suppose en outre que pour tout \\theta \\in \\Theta, Q_{\\theta} est absolument continue par rapport à une mesure \\nu sur \\mathcal{X}. Dans ce cas, en notant q(\\theta, x)=\\frac{d Q_{\\theta}}{d \\nu}(x)\n\net en prenant \\mu=\\nu^{\\otimes n} on a la vraisemblance qui s’écrit sous la forme \\mathbb{P}(\\theta, \\mathbf{x})=\\prod_{i=1}^{n} q\\left(\\theta, x_{i}\\right)\n\n et donc \\hat{\\theta}_{n}=\\arg \\max _{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i=1}^{n} \\log \\left[q\\left(\\theta, x_{i}\\right)\\right]\n\n avec la convention \\log (0)=-\\infty .\n\nExemple. (Modèle de Bernoulli)\n\nSoit Q_{\\theta_{0}}=\\mathcal{B}(\\theta) avec \\theta \\in[0,1]=\\Theta. Pour tout \\theta \\in] 0,1[ et x \\in\\{0,1\\} q(\\theta, x)=\\theta^{x}(1-\\theta)^{1-x}=(1-\\theta) \\exp \\left[x \\log \\left(\\frac{\\theta}{1-\\theta}\\right)\\right]\n\n et donc l’estimateur du maximum de vraisemblance doit maximiser dans l’intervalle [0,1]. \\log \\left(\\theta^{S_{n}}(1-\\theta)^{n-S_{n}}\\right)=S_{n} \\log \\left(\\frac{\\theta}{1-\\theta}\\right)+n \\log (1-\\theta)\n\n avec S_n = \\sum_{i} x_i ce qui conduit à \\hat{\\theta}_{n}=\\bar{\\mathbf{x}} en résolvant l’équation \\nabla \\log(q(\\theta, x)) = 0.\n\nAnirban, DasGupta. 2011. Probability for Statistics and Machine Learning. Springer.\n\nPardoux, Etienne. 2015. Intégration Set Probabilité. Université Aix Marseille.\n\nhttp://​docs​.anaconda​.com​/anaconda​/navigator/","type":"content","url":"/chapter2#estimation-par-maximum-de-vraisemblance","position":37},{"hierarchy":{"lvl1":"Bienvenue"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Bienvenue"},"content":"Bienvenue dans ce livre sur l’Apprentissage Automatique, une ressource complète et entièrement accessible en français. Cet ouvrage s’adresse aux chercheurs, étudiants et praticiens francophones, en particulier à la jeunesse africaine, qui souhaitent maîtriser les concepts fondamentaux et avancés de l’intelligence artificielle à travers des explications claires et contextualisées.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"À propos de ce livre"},"type":"lvl3","url":"/#id-propos-de-ce-livre","position":2},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"À propos de ce livre"},"content":"Ce livre couvre un large éventail de sujets, allant des bases mathématiques essentielles aux techniques modernes de deep learning. Chaque chapitre est conçu de manière progressive et pédagogique, en s’appuyant sur des exemples concrets et culturellement familiers, inspirés des réalités africaines (éducation, agriculture, finance mobile, santé, médias, langues locales, etc.), afin de rendre les notions techniques plus intuitives et directement applicables. L’objectif est de réduire les barrières d’entrée à l’IA en reliant les concepts abstraits à des situations du quotidien.","type":"content","url":"/#id-propos-de-ce-livre","position":3},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"À propos d’IVIA-AF"},"type":"lvl3","url":"/#id-propos-divia-af","position":4},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"À propos d’IVIA-AF"},"content":"Ce livre s’inscrit dans le cadre de l’initiative IVIA-AF (Initiative pour la Vulgarisation de l’Intelligence Artificielle dans l’Afrique francophone), une organisation engagée à démocratiser l’accès aux connaissances en IA auprès des communautés francophones d’Afrique et de la diaspora. IVIA-AF promeut une approche inclusive, contextualisée et orientée vers l’autonomisation de la jeunesse, en encourageant l’apprentissage, la contribution communautaire et l’innovation locale.\n\nEn savoir plus\n\nPour découvrir notre mission complète, nos autres projets, notre équipe et nos initiatives, visitez notre site web principal : www.ivia.africa\n\nStatut du livre\n\nCe livre est en cours de développement. Certains chapitres sont actuellement disponibles (marqués avec des liens cliquables), tandis que d’autres sont en cours de conversion depuis LaTeX vers Markdown et seront ajoutés progressivement.","type":"content","url":"/#id-propos-divia-af","position":5},{"hierarchy":{"lvl1":"Bienvenue","lvl2":"Table des Matières"},"type":"lvl2","url":"/#table-des-mati-res","position":6},{"hierarchy":{"lvl1":"Bienvenue","lvl2":"Table des Matières"},"content":"Ce livre couvre les concepts fondamentaux de l’apprentissage automatique, depuis les bases mathématiques jusqu’aux techniques avancées de deep learning. Voici la structure complète de l’ouvrage :","type":"content","url":"/#table-des-mati-res","position":7},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"1. Introduction Générale à l’Apprentissage Automatique","lvl2":"Table des Matières"},"type":"lvl3","url":"/#id-1","position":8},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"1. Introduction Générale à l’Apprentissage Automatique","lvl2":"Table des Matières"},"content":"1.1 C’est quoi Apprentissage Automatique\n\n1.2 Convention Mathématiques pour le document","type":"content","url":"/#id-1","position":9},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"2. Pré-requis","lvl2":"Table des Matières"},"type":"lvl3","url":"/#id-2","position":10},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"2. Pré-requis","lvl2":"Table des Matières"},"content":"2.1 Langage Python et ses Librairies\n\n2.1.1 Installation de Python et Anaconda\n\n2.1.2 Prise en main de Python\n\n2.2 Les Bases Mathématiques pour l’Apprentissage Automatique\n\n2.2.1 Algèbre linéaire et Analyse\n\nExemples de distances\n\n2.2.2 Calcul du gradient (dérivation)\n\nDérivées de fonctions composées\n\n2.2.3 Probabilités\n\nIndépendance et conditionnement\n\nVariables aléatoires\n\nVariable aléatoire discrète\n\nVariable aléatoire continue\n\nLoi des grands nombres\n\nIntervalles de confiance\n\n2.2.4 Estimations paramétriques\n\nEstimation par la méthode des moments\n\nEstimation par maximum de vraisemblance","type":"content","url":"/#id-2","position":11},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"3. Apprentissage Supervisé","lvl2":"Table des Matières"},"type":"lvl3","url":"/#id-3-apprentissage-supervis","position":12},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"3. Apprentissage Supervisé","lvl2":"Table des Matières"},"content":"3.1 Problèmes de Régression\n\n3.1.1 La Régression Linéaire\n\nLa régression linéaire affine\n\nDescente de gradient\n\nLa régression linéaire polynomiale\n\n3.2 Les Problèmes de Classification\n\n3.2.1 L’algorithme des K plus proches voisins (K-NN)\n\nAlgorithme\n\nComment choisir la valeur de K ?\n\nLes avantages de l’algorithme de K-NN\n\nLes limitations de l’algorithme de K-NN\n\nExemple pratique\n\n3.2.2 L’algorithme du Perceptron\n\nAlgorithme\n\n3.2.3 La Régression Logistique\n\nLa régression logistique binaire\n\n3.2.4 La fonction Sigmoïde et ses propriétés\n\nEstimation du maximum de vraisemblance\n\nCas pratique\n\n3.2.5 Régression logistique multinomiale\n\n3.2.6 La fonction Softmax et ses propriétés\n\n3.2.7 Estimation du maximum de vraisemblance\n\n3.2.8 Naïve Bayes\n\nEntraînement du Naïve Bayes (Exemple Pratique)\n\n3.2.9 Machines à Vecteur de Support (Support Vector Machine: SVM en anglais)\n\n3.2.10 Conclusion","type":"content","url":"/#id-3-apprentissage-supervis","position":13},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"4. Apprentissage Non-Supervisé","lvl2":"Table des Matières"},"type":"lvl3","url":"/#id-4-apprentissage-non-supervis","position":14},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"4. Apprentissage Non-Supervisé","lvl2":"Table des Matières"},"content":"4.1 Introduction et Motivations\n\n4.2 Algorithmes de Partitionnement\n\n4.2.1 K-moyennes\n\nComment choisir la valeur de K ?\n\nK-moyennes: Algorithme\n\nK-moyenne: cas pratique\n\n4.3 Réduction de dimension\n\n4.3.1 Positionnement multidimensionnel (MDS en Anglais)\n\n4.3.2 Analyse en Composantes Principales (ACP)\n\nCas d = 2\n\nCas général (d ≥ 2)\n\nAlgorithme de l’Analyse en Composantes Principales\n\n4.4 Applications\n\n4.5 Conclusion","type":"content","url":"/#id-4-apprentissage-non-supervis","position":15},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"5. Les méthodes du noyau (Kernel methods)","lvl2":"Table des Matières"},"type":"lvl3","url":"/#id-5-les-m-thodes-du-noyau-kernel-methods","position":16},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"5. Les méthodes du noyau (Kernel methods)","lvl2":"Table des Matières"},"content":"5.1 Motivations et Rappels\n\n5.1.1 Motivations\n\n5.1.2 Rappels\n\nEspace de Hilbert\n\nQuelques propriétés et caractéristiques des espaces de Hilbert\n\n5.1.3 Noyaux et espaces de Hilbert à noyau reproduisant (RKHS)\n\n5.2 Le Noyau: définitions et propriétés\n\n5.2.1 Méthodes à noyaux générales\n\nAstuce du noyau (Kernel Trick) et théorème du représentant\n\n5.2.2 Ridge regression (Régression de Ridge), Kernel ridge regression\n\n5.2.3 Méthodes à noyaux et optimisation convexe\n\nRappels d’optimisation convexe\n\n5.3 Exemples de noyaux\n\n5.3.1 Noyau linéaire\n\n5.3.2 Noyau polynomial\n\n5.3.3 Noyau de Laplace RBF\n\n5.3.4 Noyau Gaussien\n\n5.3.5 Noyau hyperbolique tangent (Noyau Sigmoid)\n\n5.4 Travaux pratiques/méthodes à noyau\n\n5.4.1 Tutoriel: première session\n\n5.4.2 Tutoriel: deuxième session","type":"content","url":"/#id-5-les-m-thodes-du-noyau-kernel-methods","position":17},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"6. Apprentissage Profond (Deep Learning)","lvl2":"Table des Matières"},"type":"lvl3","url":"/#id-6-apprentissage-profond-deep-learning","position":18},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"6. Apprentissage Profond (Deep Learning)","lvl2":"Table des Matières"},"content":"6.1 Introduction, motivation et contexte\n\n6.2 Pourquoi les réseaux de neurones ?\n\n6.3 Définitions\n\n6.4 Réseaux de neurones artificiels\n\n6.4.1 Le Neurone\n\n6.4.2 La fonction d’activation\n\nLa fonction de seuil (Threshold function)\n\nLa fonction Sigmoïde (Sigmoid function)\n\nLa fonction de redressement (Rectifier en Anglais)\n\nLa fonction tangente hyperbolique (Hyperbolic Tangent (tanh))\n\n6.4.3 Comment fonctionne le réseau de neurone ?\n\n6.4.4 Comment les réseaux de neurones apprennent ?\n\n6.4.5 Descente graduelle (Gradient Descent)\n\n6.4.6 Descente graduelle stochastique (Stochastic Gradient Descent SGD)\n\n6.4.7 Rétropropagation (Backpropagation)\n\n6.5 Réseaux de neurones adaptés au traitement de séquences\n\n6.5.1 Introduction\n\n6.5.2 Architecture de Réseaux de Neurones Récurrents (RNR)\n\n6.5.3 Rétro-propagation à travers le temps\n\n6.5.4 Les Challenges dans l’entraînement des RNR\n\n6.5.5 Long Short-Term Memory (LSTM)\n\n6.6 Réseaux de neurones en couches convolutionnelles\n\n6.6.1 Architecture du Réseaux de neurones en couches convolutionnelles (CNN)\n\n6.6.2 L’opération de convolution\n\n6.7 Travaux pratiques/méthodes à noyau\n\n6.7.1 Tutoriel: première session\n\n6.7.2 Tutoriel: deuxième session","type":"content","url":"/#id-6-apprentissage-profond-deep-learning","position":19},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"Contribution","lvl2":"Table des Matières"},"type":"lvl3","url":"/#contribution","position":20},{"hierarchy":{"lvl1":"Bienvenue","lvl3":"Contribution","lvl2":"Table des Matières"},"content":"Ce projet est une initiative collaborative et open-source. Nous accueillons chaleureusement les contributions de la communauté francophone en intelligence artificielle. Que vous souhaitiez corriger des erreurs, améliorer des explications, ou ajouter de nouveaux contenus, votre participation est précieuse.\n\nRepository GitHub : \n\ngithub​.com​/IVIA​-AF​/livre\n\nContact : \n\ncontact@ivia.africa\n\nSite web : \n\nwww.ivia.africa\n\nPour plus d’informations sur IVIA-AF, nos projets et notre équipe, visitez \n\nwww.ivia.africa","type":"content","url":"/#contribution","position":21}]}